{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visiont3lab/deep-learning-course/blob/main/colab/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ki_9emN-Nh"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrh2RbiWNw2A"
      },
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "#!pip install torchsummary\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset,Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "# Loss function pytorch: https://neptune.ai/blog/pytorch-loss-functions\n",
        "import copy\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxJ3655JN8S4"
      },
      "source": [
        "## Neural Network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l18NVUALSl3M"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOpy-O6GYJXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b706711-d00c-4f37-a6f6-f94cbbb93532"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/visiont3lab/deep-learning-course/main/data/covid19-ita-regioni.csv\")\n",
        "df[\"data\"] = [ datetime.strptime(d, \"%Y-%m-%d\") for d in df[\"data\"]]\n",
        "#df_f = df[df[\"data\"]>datetime(2020,11,6)].copy()\n",
        "df_f = df[df[\"zona\"]!=\"unknown\"]\n",
        "inputs = [\"data\",\"denominazione_regione\",\"zona\",\"ricoverati_con_sintomi\",\"terapia_intensiva\",\n",
        "        \"totale_ospedalizzati\",\"totale_positivi\",\"isolamento_domiciliare\",\n",
        "        \"deceduti\",\"dimessi_guariti\",\"nuovi_positivi\",\"totale_casi\",\"tamponi\"]\n",
        "df_f = df_f[inputs]\n",
        "df_f = df_f.drop(columns=[\"data\",\"denominazione_regione\"])\n",
        "#display(df_f)\n",
        "\n",
        "#Y = np.array([dict_names[d] for d in df_Y],dtype=np.float) #.reshape(-1,1)\n",
        "#print(f\"X shape: {X.shape} , Y shape: {Y.shape}\")\n",
        "\n",
        "dict_names = {\"bianca\":0,\"gialla\": 1, \"arancione\": 2, \"rossa\": 3}\n",
        "Y = df_f.pop(\"zona\").tolist()\n",
        "Y = np.array ( [ dict_names[e] for e in Y] , dtype=np.float32).reshape(-1,1)\n",
        "\n",
        "X = df_f.values\n",
        "\n",
        "print( X.shape )\n",
        "print( Y.shape )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2689, 10)\n",
            "(2689, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4yFxS_Id-LN"
      },
      "source": [
        "## Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTsVWGUOd_4O",
        "outputId": "9c94669a-096a-4faa-a108-19f4728c1296"
      },
      "source": [
        "class ClassificationNet(nn.Module):\n",
        "    def __init__(self,num_inputs, num_classes):\n",
        "        super(ClassificationNet,self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.fc1 = nn.Linear(num_inputs,200)\n",
        "        self.fc2 = nn.Linear(200,100)\n",
        "        self.fc3 = nn.Linear(100,50)\n",
        "        self.fc4 = nn.Linear(50,self.num_classes)\n",
        "    def forward(self,x):\n",
        "        # torch.sigmoid, torch.tanh, torch.relu\n",
        "        x = torch.tanh(self.fc1(x)) \n",
        "        x = torch.tanh(self.fc2(x))\n",
        "        x = torch.tanh(self.fc3(x))\n",
        "        x = torch.log_softmax(self.fc4(x),dim=-1) # sarebbe dim=1  print(self.fc3(x)) print(self.fc3(x).sum(dim=-1))\n",
        "        return x\n",
        "\n",
        "CN = ClassificationNet(num_inputs=10, num_classes=4)\n",
        "summary(CN,input_size=(1,10),batch_size=-1, device='cpu')\n",
        "#print(CN)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 200]           2,200\n",
            "            Linear-2               [-1, 1, 100]          20,100\n",
            "            Linear-3                [-1, 1, 50]           5,050\n",
            "            Linear-4                 [-1, 1, 4]             204\n",
            "================================================================\n",
            "Total params: 27,554\n",
            "Trainable params: 27,554\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.11\n",
            "Estimated Total Size (MB): 0.11\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHwKMpshd37u"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0LVCoZ_cLjS",
        "outputId": "c8a8351a-c537-49e1-c526-622769dc503e"
      },
      "source": [
        "# Training and Test Set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,shuffle=True,random_state=2)\n",
        "print(f\"X Train shape: {X_train.shape} , X Test shape: {X_test.shape}\")\n",
        "\n",
        "# Normalization\n",
        "C_mean = np.mean(X)\n",
        "C_std = np.std(X)\n",
        "C_min = np.min(X)\n",
        "C_max = np.max(X)\n",
        "\n",
        "# Tensor Dataset Che converte i dati da numpy a Pytorch\n",
        "class CustomTensorDataset(Dataset):\n",
        "    def __init__(self, x,y,mean,std):\n",
        "        x = (x - mean)/std           # Standard Scaler \n",
        "        #x = (x - min) / (max - min) # Min Max Scaler\n",
        "        self.x = torch.from_numpy(x).type(torch.float32)\n",
        "        self.y = torch.from_numpy(y).type(torch.LongTensor).reshape(-1)\n",
        "    def __getitem__(self, index):\n",
        "        x = self.x[index]\n",
        "        y = self.y[index]\n",
        "        return x, y\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "# Dataset generator creation\n",
        "train_ds = CustomTensorDataset(X_train,Y_train,C_mean,C_std)\n",
        "test_ds = CustomTensorDataset(X_test,Y_test,C_mean,C_std)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train shape: (1882, 10) , X Test shape: (807, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPmSf8Xzfx8a"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyA8HmPQpWuS"
      },
      "source": [
        "* numero di epoche\n",
        "* learning rate\n",
        "* batch size\n",
        "* aggiornare la struttura della rete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arHLuhtQgj9l"
      },
      "source": [
        "# validation: metric regression\n",
        "def metrics_func_regression(target, output):\n",
        "    # Comptue mean squaer error (Migliora quanto piu' ci avviciniamo a zero)\n",
        "    mse = torch.sum((output - target) ** 2)\n",
        "    return mse\n",
        "\n",
        "# validation metric classification\n",
        "def metrics_func_classification(target, output):\n",
        "    # Compute number of correct prediction\n",
        "    pred = output.argmax(dim=-1,keepdim=True)\n",
        "    corrects =pred.eq(target.reshape(pred.shape)).sum().item()\n",
        "    return -corrects # minus for coeherence with best result is the most negative one\n",
        "\n",
        "# training: loss calculation and backward step\n",
        "def loss_batch(loss_func,metric_func, xb,yb,yb_h, opt=None):\n",
        "    # obtain loss\n",
        "    loss = loss_func(yb_h, yb)\n",
        "    # obtain performance metric \n",
        "    with torch.no_grad():\n",
        "        metric_b = metric_func(yb,yb_h)\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    return loss.item(), metric_b\n",
        "\n",
        "# one epoch training\n",
        "def loss_epoch(model, loss_func,metric_func, dataset_dl, sanity_check,opt, device):\n",
        "    loss = 0.0\n",
        "    metric = 0.0\n",
        "    len_data = float(len(dataset_dl.dataset))\n",
        "    # get batch data\n",
        "    for xb,yb in dataset_dl:    \n",
        "        # send to cuda the data (batch size)\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        # obtain model output \n",
        "        yb_h = model.forward(xb)\n",
        "        # loss and metric Calculation\n",
        "        loss_b, metric_b = loss_batch(loss_func,metric_func, xb,yb,yb_h,opt)\n",
        "        # update loss\n",
        "        loss += loss_b\n",
        "        # update metric\n",
        "        if metric_b is not None:\n",
        "            metric+=metric_b \n",
        "        if sanity_check is True:\n",
        "            break\n",
        "    # average loss\n",
        "    loss /=len_data\n",
        "    # average metric\n",
        "    metric /=len_data\n",
        "    return loss, metric\n",
        "\n",
        "# get learning rate from optimizer\n",
        "def get_lr(opt):\n",
        "    # opt.param_groups[0]['lr']\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group[\"lr\"]\n",
        "\n",
        "# trainig - test loop\n",
        "def train_test(params):\n",
        "    # --> extract params\n",
        "    model = params[\"model\"]\n",
        "    loss_func=params[\"loss_func\"]\n",
        "    metric_func=params[\"metric_func\"]\n",
        "    num_epochs=params[\"num_epochs\"]\n",
        "    opt=params[\"optimizer\"]\n",
        "    lr_scheduler=params[\"lr_scheduler\"]\n",
        "    train_dl=params[\"train_dl\"]\n",
        "    test_dl=params[\"test_dl\"]\n",
        "    device=params[\"device\"]\n",
        "    continue_training=params[\"continue_training\"]\n",
        "    sanity_check=params[\"sanity_check\"]\n",
        "    path2weigths=params[\"path2weigths\"]\n",
        "    # --> send model to device and print device\n",
        "    model = model.to(device)\n",
        "    print(\"--> training device %s\" % (device))\n",
        "    # --> if continue_training=True load path2weigths\n",
        "    if continue_training==True and os.path.isfile(path2weigths):\n",
        "        print(\"--> continue training  from last best weights\")\n",
        "        weights = torch.load(path2weigths)\n",
        "        model.load_state_dict(weights)\n",
        "    # --> history of loss values in each epoch\n",
        "    loss_history={\"train\": [],\"test\":[]}\n",
        "    # --> history of metric values in each epoch\n",
        "    metric_history={\"train\": [],\"test\":[]}\n",
        "    # --> a deep copy of weights for the best performing model\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    # --> initialiaze best loss to large value\n",
        "    best_loss=float(\"inf\")\n",
        "    # --> main loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # --> get learning rate\n",
        "        lr = get_lr(opt)\n",
        "        print(\"----\\nEpoch %s/%s, lr=%.6f\" % (epoch+1,num_epochs,lr))\n",
        "        # --> train model on training dataset\n",
        "        # we tell to the model to enter in train state. it is important because\n",
        "        # there are somelayers like dropout, batchnorm that behaves \n",
        "        # differently between train and test\n",
        "        model.train()\n",
        "        train_loss,train_metric = loss_epoch(model, loss_func, metric_func,train_dl,sanity_check, opt,device)\n",
        "        # --> collect loss and metric for training dataset\n",
        "        loss_history[\"train\"].append(train_loss)\n",
        "        metric_history[\"train\"].append(train_metric)\n",
        "        # --> tell the model to be in test (validation) mode\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_loss, test_metric = loss_epoch(model, loss_func, metric_func, test_dl,sanity_check,opt=None,device=device)\n",
        "        # --> collect loss and metric for test dataset\n",
        "        loss_history[\"test\"].append(test_loss)\n",
        "        metric_history[\"test\"].append(test_metric)\n",
        "        # --> store best model\n",
        "        if test_loss < best_loss:\n",
        "            print(\"--> model improved! --> saved to %s\" %(path2weigths))\n",
        "            best_loss = test_loss\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            # --> store weights into local file\n",
        "            torch.save(model.state_dict(),path2weigths)\n",
        "        # --> learning rate scheduler\n",
        "        lr_scheduler.step()\n",
        "        print(\"--> train_loss: %.6f, test_loss: %.6f, train_metric: %.3f, test_metric: %.3f\" % (train_loss,test_loss,train_metric,test_metric))\n",
        "    # --> load best weights\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    return model, loss_history,metric_history\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx_Ha_93hDfo",
        "outputId": "44afe5e8-7b23-4c34-dc0b-c12270682e6e"
      },
      "source": [
        "# Setup GPU Device\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "\n",
        "# Regression\n",
        "model = ClassificationNet(num_inputs=10, num_classes=4).to(device)\n",
        "loss_func = nn.NLLLoss(reduction=\"sum\")  #nn.BCELoss  \n",
        "opt = optim.Adam(model.parameters(),lr=0.001)\n",
        "train_dl = DataLoader(train_ds,batch_size=124,shuffle=True)\n",
        "test_dl = DataLoader(test_ds,batch_size=124,shuffle=True)\n",
        "\n",
        "# Regression\n",
        "\n",
        "# Setup GPU Device\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.999)  #  lr = lr * gamma ** last_epoch\n",
        "params = {\n",
        "    \"model\":                 model,\n",
        "    \"loss_func\":             loss_func, \n",
        "    \"metric_func\":           metrics_func_classification,\n",
        "    \"num_epochs\":            300,\n",
        "    \"optimizer\":             opt,\n",
        "    \"lr_scheduler\":          lr_scheduler,\n",
        "    \"train_dl\":              train_dl,\n",
        "    \"test_dl\":               test_dl,\n",
        "    \"device\":                device,  \n",
        "    \"continue_training\" :    False,  # continue training from last save weights\n",
        "    \"sanity_check\":          False, # if true we only do one batch per epoch\n",
        "    \"path2weigths\":          \"./weights_classification.pt\"  \n",
        "} \n",
        "model, loss_history,metric_history = train_test(params)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--> training device cpu\n",
            "----\n",
            "Epoch 1/300, lr=0.001000\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.170238, test_loss: 1.102329, train_metric: -0.370, test_metric: -0.372\n",
            "----\n",
            "Epoch 2/300, lr=0.000999\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.105318, test_loss: 1.095627, train_metric: -0.386, test_metric: -0.413\n",
            "----\n",
            "Epoch 3/300, lr=0.000998\n",
            "--> train_loss: 1.101353, test_loss: 1.096018, train_metric: -0.397, test_metric: -0.413\n",
            "----\n",
            "Epoch 4/300, lr=0.000997\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.106576, test_loss: 1.094528, train_metric: -0.389, test_metric: -0.372\n",
            "----\n",
            "Epoch 5/300, lr=0.000996\n",
            "--> train_loss: 1.102463, test_loss: 1.095452, train_metric: -0.410, test_metric: -0.456\n",
            "----\n",
            "Epoch 6/300, lr=0.000995\n",
            "--> train_loss: 1.100696, test_loss: 1.097028, train_metric: -0.419, test_metric: -0.372\n",
            "----\n",
            "Epoch 7/300, lr=0.000994\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.098075, test_loss: 1.087384, train_metric: -0.406, test_metric: -0.450\n",
            "----\n",
            "Epoch 8/300, lr=0.000993\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.098131, test_loss: 1.085721, train_metric: -0.427, test_metric: -0.467\n",
            "----\n",
            "Epoch 9/300, lr=0.000992\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.095183, test_loss: 1.085545, train_metric: -0.426, test_metric: -0.455\n",
            "----\n",
            "Epoch 10/300, lr=0.000991\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.093810, test_loss: 1.083300, train_metric: -0.442, test_metric: -0.467\n",
            "----\n",
            "Epoch 11/300, lr=0.000990\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.091812, test_loss: 1.079870, train_metric: -0.429, test_metric: -0.435\n",
            "----\n",
            "Epoch 12/300, lr=0.000989\n",
            "--> train_loss: 1.087754, test_loss: 1.083304, train_metric: -0.419, test_metric: -0.462\n",
            "----\n",
            "Epoch 13/300, lr=0.000988\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.088704, test_loss: 1.076489, train_metric: -0.430, test_metric: -0.450\n",
            "----\n",
            "Epoch 14/300, lr=0.000987\n",
            "--> train_loss: 1.085188, test_loss: 1.077907, train_metric: -0.444, test_metric: -0.457\n",
            "----\n",
            "Epoch 15/300, lr=0.000986\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.085367, test_loss: 1.075207, train_metric: -0.444, test_metric: -0.456\n",
            "----\n",
            "Epoch 16/300, lr=0.000985\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.084171, test_loss: 1.073627, train_metric: -0.442, test_metric: -0.461\n",
            "----\n",
            "Epoch 17/300, lr=0.000984\n",
            "--> train_loss: 1.082858, test_loss: 1.074206, train_metric: -0.451, test_metric: -0.450\n",
            "----\n",
            "Epoch 18/300, lr=0.000983\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.080634, test_loss: 1.070200, train_metric: -0.441, test_metric: -0.480\n",
            "----\n",
            "Epoch 19/300, lr=0.000982\n",
            "--> train_loss: 1.079453, test_loss: 1.075095, train_metric: -0.456, test_metric: -0.440\n",
            "----\n",
            "Epoch 20/300, lr=0.000981\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.080171, test_loss: 1.067074, train_metric: -0.451, test_metric: -0.455\n",
            "----\n",
            "Epoch 21/300, lr=0.000980\n",
            "--> train_loss: 1.078272, test_loss: 1.069919, train_metric: -0.440, test_metric: -0.451\n",
            "----\n",
            "Epoch 22/300, lr=0.000979\n",
            "--> train_loss: 1.075948, test_loss: 1.071161, train_metric: -0.445, test_metric: -0.446\n",
            "----\n",
            "Epoch 23/300, lr=0.000978\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.069657, test_loss: 1.062810, train_metric: -0.433, test_metric: -0.451\n",
            "----\n",
            "Epoch 24/300, lr=0.000977\n",
            "--> train_loss: 1.066159, test_loss: 1.065372, train_metric: -0.447, test_metric: -0.455\n",
            "----\n",
            "Epoch 25/300, lr=0.000976\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.064149, test_loss: 1.059277, train_metric: -0.449, test_metric: -0.439\n",
            "----\n",
            "Epoch 26/300, lr=0.000975\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.062575, test_loss: 1.052941, train_metric: -0.441, test_metric: -0.457\n",
            "----\n",
            "Epoch 27/300, lr=0.000974\n",
            "--> train_loss: 1.059629, test_loss: 1.066536, train_metric: -0.449, test_metric: -0.418\n",
            "----\n",
            "Epoch 28/300, lr=0.000973\n",
            "--> train_loss: 1.070465, test_loss: 1.071297, train_metric: -0.434, test_metric: -0.447\n",
            "----\n",
            "Epoch 29/300, lr=0.000972\n",
            "--> train_loss: 1.056311, test_loss: 1.059315, train_metric: -0.455, test_metric: -0.458\n",
            "----\n",
            "Epoch 30/300, lr=0.000971\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.055581, test_loss: 1.047963, train_metric: -0.440, test_metric: -0.457\n",
            "----\n",
            "Epoch 31/300, lr=0.000970\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.049969, test_loss: 1.046335, train_metric: -0.451, test_metric: -0.439\n",
            "----\n",
            "Epoch 32/300, lr=0.000969\n",
            "--> train_loss: 1.049066, test_loss: 1.060926, train_metric: -0.456, test_metric: -0.466\n",
            "----\n",
            "Epoch 33/300, lr=0.000968\n",
            "--> train_loss: 1.051162, test_loss: 1.062484, train_metric: -0.459, test_metric: -0.445\n",
            "----\n",
            "Epoch 34/300, lr=0.000968\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.041852, test_loss: 1.036429, train_metric: -0.463, test_metric: -0.442\n",
            "----\n",
            "Epoch 35/300, lr=0.000967\n",
            "--> train_loss: 1.038015, test_loss: 1.037707, train_metric: -0.456, test_metric: -0.446\n",
            "----\n",
            "Epoch 36/300, lr=0.000966\n",
            "--> train_loss: 1.033587, test_loss: 1.040487, train_metric: -0.468, test_metric: -0.447\n",
            "----\n",
            "Epoch 37/300, lr=0.000965\n",
            "--> train_loss: 1.031489, test_loss: 1.044324, train_metric: -0.478, test_metric: -0.450\n",
            "----\n",
            "Epoch 38/300, lr=0.000964\n",
            "--> train_loss: 1.035411, test_loss: 1.041098, train_metric: -0.457, test_metric: -0.455\n",
            "----\n",
            "Epoch 39/300, lr=0.000963\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.030172, test_loss: 1.031477, train_metric: -0.466, test_metric: -0.447\n",
            "----\n",
            "Epoch 40/300, lr=0.000962\n",
            "--> train_loss: 1.032366, test_loss: 1.032017, train_metric: -0.472, test_metric: -0.449\n",
            "----\n",
            "Epoch 41/300, lr=0.000961\n",
            "--> train_loss: 1.024072, test_loss: 1.032953, train_metric: -0.476, test_metric: -0.463\n",
            "----\n",
            "Epoch 42/300, lr=0.000960\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.027318, test_loss: 1.026943, train_metric: -0.480, test_metric: -0.470\n",
            "----\n",
            "Epoch 43/300, lr=0.000959\n",
            "--> train_loss: 1.024582, test_loss: 1.030519, train_metric: -0.468, test_metric: -0.451\n",
            "----\n",
            "Epoch 44/300, lr=0.000958\n",
            "--> train_loss: 1.023093, test_loss: 1.027770, train_metric: -0.478, test_metric: -0.462\n",
            "----\n",
            "Epoch 45/300, lr=0.000957\n",
            "--> train_loss: 1.026448, test_loss: 1.041832, train_metric: -0.464, test_metric: -0.462\n",
            "----\n",
            "Epoch 46/300, lr=0.000956\n",
            "--> train_loss: 1.028960, test_loss: 1.028232, train_metric: -0.467, test_metric: -0.461\n",
            "----\n",
            "Epoch 47/300, lr=0.000955\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.014776, test_loss: 1.024815, train_metric: -0.469, test_metric: -0.462\n",
            "----\n",
            "Epoch 48/300, lr=0.000954\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.023231, test_loss: 1.022389, train_metric: -0.476, test_metric: -0.465\n",
            "----\n",
            "Epoch 49/300, lr=0.000953\n",
            "--> train_loss: 1.014413, test_loss: 1.029964, train_metric: -0.474, test_metric: -0.466\n",
            "----\n",
            "Epoch 50/300, lr=0.000952\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.014400, test_loss: 1.020213, train_metric: -0.478, test_metric: -0.478\n",
            "----\n",
            "Epoch 51/300, lr=0.000951\n",
            "--> train_loss: 1.011879, test_loss: 1.023953, train_metric: -0.474, test_metric: -0.466\n",
            "----\n",
            "Epoch 52/300, lr=0.000950\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.014413, test_loss: 1.018392, train_metric: -0.477, test_metric: -0.476\n",
            "----\n",
            "Epoch 53/300, lr=0.000949\n",
            "--> train_loss: 1.012229, test_loss: 1.018715, train_metric: -0.467, test_metric: -0.442\n",
            "----\n",
            "Epoch 54/300, lr=0.000948\n",
            "--> train_loss: 1.013667, test_loss: 1.019786, train_metric: -0.472, test_metric: -0.471\n",
            "----\n",
            "Epoch 55/300, lr=0.000947\n",
            "--> train_loss: 1.007672, test_loss: 1.018657, train_metric: -0.491, test_metric: -0.472\n",
            "----\n",
            "Epoch 56/300, lr=0.000946\n",
            "--> train_loss: 1.010286, test_loss: 1.019845, train_metric: -0.481, test_metric: -0.449\n",
            "----\n",
            "Epoch 57/300, lr=0.000946\n",
            "--> train_loss: 1.008815, test_loss: 1.024646, train_metric: -0.476, test_metric: -0.458\n",
            "----\n",
            "Epoch 58/300, lr=0.000945\n",
            "--> train_loss: 1.011020, test_loss: 1.034374, train_metric: -0.494, test_metric: -0.472\n",
            "----\n",
            "Epoch 59/300, lr=0.000944\n",
            "--> train_loss: 1.008962, test_loss: 1.020216, train_metric: -0.484, test_metric: -0.467\n",
            "----\n",
            "Epoch 60/300, lr=0.000943\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.008365, test_loss: 1.015710, train_metric: -0.471, test_metric: -0.465\n",
            "----\n",
            "Epoch 61/300, lr=0.000942\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.005645, test_loss: 1.014087, train_metric: -0.490, test_metric: -0.480\n",
            "----\n",
            "Epoch 62/300, lr=0.000941\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.003916, test_loss: 1.012940, train_metric: -0.481, test_metric: -0.489\n",
            "----\n",
            "Epoch 63/300, lr=0.000940\n",
            "--> train_loss: 1.000174, test_loss: 1.018797, train_metric: -0.486, test_metric: -0.440\n",
            "----\n",
            "Epoch 64/300, lr=0.000939\n",
            "--> train_loss: 1.001082, test_loss: 1.019359, train_metric: -0.487, test_metric: -0.478\n",
            "----\n",
            "Epoch 65/300, lr=0.000938\n",
            "--> train_loss: 1.005255, test_loss: 1.019002, train_metric: -0.475, test_metric: -0.460\n",
            "----\n",
            "Epoch 66/300, lr=0.000937\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.001750, test_loss: 1.010351, train_metric: -0.483, test_metric: -0.493\n",
            "----\n",
            "Epoch 67/300, lr=0.000936\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 1.001759, test_loss: 1.009703, train_metric: -0.486, test_metric: -0.471\n",
            "----\n",
            "Epoch 68/300, lr=0.000935\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.998700, test_loss: 1.005365, train_metric: -0.482, test_metric: -0.482\n",
            "----\n",
            "Epoch 69/300, lr=0.000934\n",
            "--> train_loss: 1.001292, test_loss: 1.011102, train_metric: -0.493, test_metric: -0.477\n",
            "----\n",
            "Epoch 70/300, lr=0.000933\n",
            "--> train_loss: 1.001566, test_loss: 1.007008, train_metric: -0.490, test_metric: -0.482\n",
            "----\n",
            "Epoch 71/300, lr=0.000932\n",
            "--> train_loss: 1.004708, test_loss: 1.005956, train_metric: -0.494, test_metric: -0.483\n",
            "----\n",
            "Epoch 72/300, lr=0.000931\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.996910, test_loss: 1.000881, train_metric: -0.491, test_metric: -0.465\n",
            "----\n",
            "Epoch 73/300, lr=0.000930\n",
            "--> train_loss: 0.992896, test_loss: 1.011212, train_metric: -0.479, test_metric: -0.471\n",
            "----\n",
            "Epoch 74/300, lr=0.000930\n",
            "--> train_loss: 0.992715, test_loss: 1.002454, train_metric: -0.493, test_metric: -0.483\n",
            "----\n",
            "Epoch 75/300, lr=0.000929\n",
            "--> train_loss: 0.993800, test_loss: 1.005813, train_metric: -0.487, test_metric: -0.472\n",
            "----\n",
            "Epoch 76/300, lr=0.000928\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.998256, test_loss: 1.000839, train_metric: -0.482, test_metric: -0.491\n",
            "----\n",
            "Epoch 77/300, lr=0.000927\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.991142, test_loss: 0.999862, train_metric: -0.496, test_metric: -0.486\n",
            "----\n",
            "Epoch 78/300, lr=0.000926\n",
            "--> train_loss: 0.990986, test_loss: 1.007335, train_metric: -0.493, test_metric: -0.475\n",
            "----\n",
            "Epoch 79/300, lr=0.000925\n",
            "--> train_loss: 0.989914, test_loss: 1.000637, train_metric: -0.496, test_metric: -0.478\n",
            "----\n",
            "Epoch 80/300, lr=0.000924\n",
            "--> train_loss: 0.987817, test_loss: 1.013267, train_metric: -0.498, test_metric: -0.480\n",
            "----\n",
            "Epoch 81/300, lr=0.000923\n",
            "--> train_loss: 0.995827, test_loss: 1.017743, train_metric: -0.491, test_metric: -0.460\n",
            "----\n",
            "Epoch 82/300, lr=0.000922\n",
            "--> train_loss: 0.995425, test_loss: 1.006814, train_metric: -0.485, test_metric: -0.481\n",
            "----\n",
            "Epoch 83/300, lr=0.000921\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.987115, test_loss: 0.993549, train_metric: -0.498, test_metric: -0.497\n",
            "----\n",
            "Epoch 84/300, lr=0.000920\n",
            "--> train_loss: 0.980842, test_loss: 0.999352, train_metric: -0.495, test_metric: -0.486\n",
            "----\n",
            "Epoch 85/300, lr=0.000919\n",
            "--> train_loss: 0.982865, test_loss: 0.995375, train_metric: -0.502, test_metric: -0.485\n",
            "----\n",
            "Epoch 86/300, lr=0.000918\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.987110, test_loss: 0.993271, train_metric: -0.502, test_metric: -0.493\n",
            "----\n",
            "Epoch 87/300, lr=0.000918\n",
            "--> train_loss: 0.980330, test_loss: 1.000585, train_metric: -0.504, test_metric: -0.482\n",
            "----\n",
            "Epoch 88/300, lr=0.000917\n",
            "--> train_loss: 0.982443, test_loss: 0.994412, train_metric: -0.486, test_metric: -0.481\n",
            "----\n",
            "Epoch 89/300, lr=0.000916\n",
            "--> train_loss: 0.986105, test_loss: 1.008260, train_metric: -0.506, test_metric: -0.467\n",
            "----\n",
            "Epoch 90/300, lr=0.000915\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.981077, test_loss: 0.984144, train_metric: -0.503, test_metric: -0.485\n",
            "----\n",
            "Epoch 91/300, lr=0.000914\n",
            "--> train_loss: 0.976455, test_loss: 0.988464, train_metric: -0.498, test_metric: -0.476\n",
            "----\n",
            "Epoch 92/300, lr=0.000913\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.974344, test_loss: 0.982014, train_metric: -0.512, test_metric: -0.475\n",
            "----\n",
            "Epoch 93/300, lr=0.000912\n",
            "--> train_loss: 0.973938, test_loss: 0.991916, train_metric: -0.511, test_metric: -0.458\n",
            "----\n",
            "Epoch 94/300, lr=0.000911\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.973733, test_loss: 0.978847, train_metric: -0.511, test_metric: -0.478\n",
            "----\n",
            "Epoch 95/300, lr=0.000910\n",
            "--> train_loss: 0.971637, test_loss: 0.990403, train_metric: -0.502, test_metric: -0.468\n",
            "----\n",
            "Epoch 96/300, lr=0.000909\n",
            "--> train_loss: 0.974439, test_loss: 0.981130, train_metric: -0.505, test_metric: -0.473\n",
            "----\n",
            "Epoch 97/300, lr=0.000908\n",
            "--> train_loss: 0.971272, test_loss: 0.986117, train_metric: -0.504, test_metric: -0.466\n",
            "----\n",
            "Epoch 98/300, lr=0.000908\n",
            "--> train_loss: 0.968003, test_loss: 0.982407, train_metric: -0.515, test_metric: -0.481\n",
            "----\n",
            "Epoch 99/300, lr=0.000907\n",
            "--> train_loss: 0.968970, test_loss: 0.982806, train_metric: -0.509, test_metric: -0.499\n",
            "----\n",
            "Epoch 100/300, lr=0.000906\n",
            "--> train_loss: 0.967360, test_loss: 0.981199, train_metric: -0.521, test_metric: -0.506\n",
            "----\n",
            "Epoch 101/300, lr=0.000905\n",
            "--> train_loss: 0.966509, test_loss: 0.979780, train_metric: -0.514, test_metric: -0.493\n",
            "----\n",
            "Epoch 102/300, lr=0.000904\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.961995, test_loss: 0.971400, train_metric: -0.514, test_metric: -0.496\n",
            "----\n",
            "Epoch 103/300, lr=0.000903\n",
            "--> train_loss: 0.962725, test_loss: 0.984874, train_metric: -0.523, test_metric: -0.487\n",
            "----\n",
            "Epoch 104/300, lr=0.000902\n",
            "--> train_loss: 0.962366, test_loss: 0.983626, train_metric: -0.523, test_metric: -0.499\n",
            "----\n",
            "Epoch 105/300, lr=0.000901\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.959432, test_loss: 0.971395, train_metric: -0.518, test_metric: -0.517\n",
            "----\n",
            "Epoch 106/300, lr=0.000900\n",
            "--> train_loss: 0.956967, test_loss: 0.975403, train_metric: -0.532, test_metric: -0.492\n",
            "----\n",
            "Epoch 107/300, lr=0.000899\n",
            "--> train_loss: 0.956787, test_loss: 0.972545, train_metric: -0.523, test_metric: -0.488\n",
            "----\n",
            "Epoch 108/300, lr=0.000898\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.952112, test_loss: 0.962201, train_metric: -0.525, test_metric: -0.501\n",
            "----\n",
            "Epoch 109/300, lr=0.000898\n",
            "--> train_loss: 0.954788, test_loss: 0.963290, train_metric: -0.527, test_metric: -0.497\n",
            "----\n",
            "Epoch 110/300, lr=0.000897\n",
            "--> train_loss: 0.949916, test_loss: 0.976788, train_metric: -0.519, test_metric: -0.494\n",
            "----\n",
            "Epoch 111/300, lr=0.000896\n",
            "--> train_loss: 0.956233, test_loss: 0.969263, train_metric: -0.519, test_metric: -0.506\n",
            "----\n",
            "Epoch 112/300, lr=0.000895\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.951079, test_loss: 0.958605, train_metric: -0.534, test_metric: -0.529\n",
            "----\n",
            "Epoch 113/300, lr=0.000894\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.944502, test_loss: 0.955355, train_metric: -0.529, test_metric: -0.509\n",
            "----\n",
            "Epoch 114/300, lr=0.000893\n",
            "--> train_loss: 0.941549, test_loss: 0.958450, train_metric: -0.540, test_metric: -0.515\n",
            "----\n",
            "Epoch 115/300, lr=0.000892\n",
            "--> train_loss: 0.940667, test_loss: 0.958759, train_metric: -0.533, test_metric: -0.509\n",
            "----\n",
            "Epoch 116/300, lr=0.000891\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.937243, test_loss: 0.951252, train_metric: -0.554, test_metric: -0.507\n",
            "----\n",
            "Epoch 117/300, lr=0.000890\n",
            "--> train_loss: 0.936979, test_loss: 0.956163, train_metric: -0.548, test_metric: -0.520\n",
            "----\n",
            "Epoch 118/300, lr=0.000890\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.934018, test_loss: 0.945775, train_metric: -0.547, test_metric: -0.514\n",
            "----\n",
            "Epoch 119/300, lr=0.000889\n",
            "--> train_loss: 0.931762, test_loss: 0.957782, train_metric: -0.540, test_metric: -0.507\n",
            "----\n",
            "Epoch 120/300, lr=0.000888\n",
            "--> train_loss: 0.937478, test_loss: 0.960056, train_metric: -0.539, test_metric: -0.515\n",
            "----\n",
            "Epoch 121/300, lr=0.000887\n",
            "--> train_loss: 0.945630, test_loss: 0.947641, train_metric: -0.528, test_metric: -0.525\n",
            "----\n",
            "Epoch 122/300, lr=0.000886\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.927337, test_loss: 0.945734, train_metric: -0.550, test_metric: -0.545\n",
            "----\n",
            "Epoch 123/300, lr=0.000885\n",
            "--> train_loss: 0.928518, test_loss: 0.948243, train_metric: -0.548, test_metric: -0.524\n",
            "----\n",
            "Epoch 124/300, lr=0.000884\n",
            "--> train_loss: 0.926845, test_loss: 0.950051, train_metric: -0.561, test_metric: -0.522\n",
            "----\n",
            "Epoch 125/300, lr=0.000883\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.929695, test_loss: 0.943916, train_metric: -0.546, test_metric: -0.535\n",
            "----\n",
            "Epoch 126/300, lr=0.000882\n",
            "--> train_loss: 0.918793, test_loss: 0.948259, train_metric: -0.557, test_metric: -0.504\n",
            "----\n",
            "Epoch 127/300, lr=0.000882\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.923772, test_loss: 0.941519, train_metric: -0.555, test_metric: -0.535\n",
            "----\n",
            "Epoch 128/300, lr=0.000881\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.925141, test_loss: 0.934817, train_metric: -0.535, test_metric: -0.540\n",
            "----\n",
            "Epoch 129/300, lr=0.000880\n",
            "--> train_loss: 0.915365, test_loss: 0.952756, train_metric: -0.562, test_metric: -0.509\n",
            "----\n",
            "Epoch 130/300, lr=0.000879\n",
            "--> train_loss: 0.927317, test_loss: 0.942450, train_metric: -0.525, test_metric: -0.524\n",
            "----\n",
            "Epoch 131/300, lr=0.000878\n",
            "--> train_loss: 0.923672, test_loss: 0.950095, train_metric: -0.552, test_metric: -0.535\n",
            "----\n",
            "Epoch 132/300, lr=0.000877\n",
            "--> train_loss: 0.923500, test_loss: 0.939347, train_metric: -0.565, test_metric: -0.528\n",
            "----\n",
            "Epoch 133/300, lr=0.000876\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.914201, test_loss: 0.930838, train_metric: -0.556, test_metric: -0.522\n",
            "----\n",
            "Epoch 134/300, lr=0.000875\n",
            "--> train_loss: 0.910284, test_loss: 0.942150, train_metric: -0.562, test_metric: -0.532\n",
            "----\n",
            "Epoch 135/300, lr=0.000875\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.908087, test_loss: 0.923707, train_metric: -0.569, test_metric: -0.533\n",
            "----\n",
            "Epoch 136/300, lr=0.000874\n",
            "--> train_loss: 0.899131, test_loss: 0.927843, train_metric: -0.570, test_metric: -0.528\n",
            "----\n",
            "Epoch 137/300, lr=0.000873\n",
            "--> train_loss: 0.900839, test_loss: 0.926461, train_metric: -0.561, test_metric: -0.555\n",
            "----\n",
            "Epoch 138/300, lr=0.000872\n",
            "--> train_loss: 0.900380, test_loss: 0.932439, train_metric: -0.569, test_metric: -0.528\n",
            "----\n",
            "Epoch 139/300, lr=0.000871\n",
            "--> train_loss: 0.910662, test_loss: 0.942148, train_metric: -0.569, test_metric: -0.542\n",
            "----\n",
            "Epoch 140/300, lr=0.000870\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.909016, test_loss: 0.918088, train_metric: -0.559, test_metric: -0.532\n",
            "----\n",
            "Epoch 141/300, lr=0.000869\n",
            "--> train_loss: 0.900833, test_loss: 0.927169, train_metric: -0.569, test_metric: -0.549\n",
            "----\n",
            "Epoch 142/300, lr=0.000868\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.897694, test_loss: 0.914969, train_metric: -0.568, test_metric: -0.522\n",
            "----\n",
            "Epoch 143/300, lr=0.000868\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.898695, test_loss: 0.914004, train_metric: -0.557, test_metric: -0.537\n",
            "----\n",
            "Epoch 144/300, lr=0.000867\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.892075, test_loss: 0.913894, train_metric: -0.584, test_metric: -0.538\n",
            "----\n",
            "Epoch 145/300, lr=0.000866\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.891508, test_loss: 0.906189, train_metric: -0.571, test_metric: -0.549\n",
            "----\n",
            "Epoch 146/300, lr=0.000865\n",
            "--> train_loss: 0.884748, test_loss: 0.913435, train_metric: -0.580, test_metric: -0.538\n",
            "----\n",
            "Epoch 147/300, lr=0.000864\n",
            "--> train_loss: 0.884304, test_loss: 0.915604, train_metric: -0.567, test_metric: -0.559\n",
            "----\n",
            "Epoch 148/300, lr=0.000863\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.882362, test_loss: 0.904883, train_metric: -0.578, test_metric: -0.523\n",
            "----\n",
            "Epoch 149/300, lr=0.000862\n",
            "--> train_loss: 0.881048, test_loss: 0.906212, train_metric: -0.570, test_metric: -0.553\n",
            "----\n",
            "Epoch 150/300, lr=0.000862\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.873163, test_loss: 0.899511, train_metric: -0.578, test_metric: -0.555\n",
            "----\n",
            "Epoch 151/300, lr=0.000861\n",
            "--> train_loss: 0.876628, test_loss: 0.916481, train_metric: -0.586, test_metric: -0.551\n",
            "----\n",
            "Epoch 152/300, lr=0.000860\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.877843, test_loss: 0.890604, train_metric: -0.580, test_metric: -0.571\n",
            "----\n",
            "Epoch 153/300, lr=0.000859\n",
            "--> train_loss: 0.868558, test_loss: 0.893901, train_metric: -0.587, test_metric: -0.574\n",
            "----\n",
            "Epoch 154/300, lr=0.000858\n",
            "--> train_loss: 0.870393, test_loss: 0.893156, train_metric: -0.596, test_metric: -0.545\n",
            "----\n",
            "Epoch 155/300, lr=0.000857\n",
            "--> train_loss: 0.869326, test_loss: 0.912606, train_metric: -0.577, test_metric: -0.532\n",
            "----\n",
            "Epoch 156/300, lr=0.000856\n",
            "--> train_loss: 0.871228, test_loss: 0.896479, train_metric: -0.581, test_metric: -0.546\n",
            "----\n",
            "Epoch 157/300, lr=0.000855\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.862666, test_loss: 0.890251, train_metric: -0.588, test_metric: -0.574\n",
            "----\n",
            "Epoch 158/300, lr=0.000855\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.861890, test_loss: 0.889327, train_metric: -0.594, test_metric: -0.570\n",
            "----\n",
            "Epoch 159/300, lr=0.000854\n",
            "--> train_loss: 0.858928, test_loss: 0.890746, train_metric: -0.593, test_metric: -0.564\n",
            "----\n",
            "Epoch 160/300, lr=0.000853\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.853421, test_loss: 0.885082, train_metric: -0.610, test_metric: -0.560\n",
            "----\n",
            "Epoch 161/300, lr=0.000852\n",
            "--> train_loss: 0.853825, test_loss: 0.894695, train_metric: -0.596, test_metric: -0.544\n",
            "----\n",
            "Epoch 162/300, lr=0.000851\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.850342, test_loss: 0.875513, train_metric: -0.595, test_metric: -0.570\n",
            "----\n",
            "Epoch 163/300, lr=0.000850\n",
            "--> train_loss: 0.851953, test_loss: 0.879071, train_metric: -0.587, test_metric: -0.560\n",
            "----\n",
            "Epoch 164/300, lr=0.000850\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.841769, test_loss: 0.870085, train_metric: -0.595, test_metric: -0.586\n",
            "----\n",
            "Epoch 165/300, lr=0.000849\n",
            "--> train_loss: 0.840532, test_loss: 0.873531, train_metric: -0.616, test_metric: -0.556\n",
            "----\n",
            "Epoch 166/300, lr=0.000848\n",
            "--> train_loss: 0.835537, test_loss: 0.872734, train_metric: -0.611, test_metric: -0.586\n",
            "----\n",
            "Epoch 167/300, lr=0.000847\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.841577, test_loss: 0.867343, train_metric: -0.617, test_metric: -0.553\n",
            "----\n",
            "Epoch 168/300, lr=0.000846\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.837594, test_loss: 0.866713, train_metric: -0.607, test_metric: -0.581\n",
            "----\n",
            "Epoch 169/300, lr=0.000845\n",
            "--> train_loss: 0.834007, test_loss: 0.872887, train_metric: -0.626, test_metric: -0.546\n",
            "----\n",
            "Epoch 170/300, lr=0.000844\n",
            "--> train_loss: 0.835560, test_loss: 0.873907, train_metric: -0.614, test_metric: -0.549\n",
            "----\n",
            "Epoch 171/300, lr=0.000844\n",
            "--> train_loss: 0.829212, test_loss: 0.874031, train_metric: -0.620, test_metric: -0.559\n",
            "----\n",
            "Epoch 172/300, lr=0.000843\n",
            "--> train_loss: 0.831291, test_loss: 0.878338, train_metric: -0.616, test_metric: -0.561\n",
            "----\n",
            "Epoch 173/300, lr=0.000842\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.831369, test_loss: 0.856073, train_metric: -0.613, test_metric: -0.603\n",
            "----\n",
            "Epoch 174/300, lr=0.000841\n",
            "--> train_loss: 0.823193, test_loss: 0.863969, train_metric: -0.620, test_metric: -0.595\n",
            "----\n",
            "Epoch 175/300, lr=0.000840\n",
            "--> train_loss: 0.826753, test_loss: 0.865046, train_metric: -0.621, test_metric: -0.589\n",
            "----\n",
            "Epoch 176/300, lr=0.000839\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.826949, test_loss: 0.854102, train_metric: -0.608, test_metric: -0.591\n",
            "----\n",
            "Epoch 177/300, lr=0.000839\n",
            "--> train_loss: 0.812306, test_loss: 0.877938, train_metric: -0.623, test_metric: -0.574\n",
            "----\n",
            "Epoch 178/300, lr=0.000838\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.819335, test_loss: 0.844874, train_metric: -0.632, test_metric: -0.576\n",
            "----\n",
            "Epoch 179/300, lr=0.000837\n",
            "--> train_loss: 0.820717, test_loss: 0.855773, train_metric: -0.623, test_metric: -0.577\n",
            "----\n",
            "Epoch 180/300, lr=0.000836\n",
            "--> train_loss: 0.813366, test_loss: 0.846983, train_metric: -0.620, test_metric: -0.606\n",
            "----\n",
            "Epoch 181/300, lr=0.000835\n",
            "--> train_loss: 0.814228, test_loss: 0.856221, train_metric: -0.632, test_metric: -0.591\n",
            "----\n",
            "Epoch 182/300, lr=0.000834\n",
            "--> train_loss: 0.811850, test_loss: 0.851800, train_metric: -0.630, test_metric: -0.585\n",
            "----\n",
            "Epoch 183/300, lr=0.000834\n",
            "--> train_loss: 0.806816, test_loss: 0.859359, train_metric: -0.639, test_metric: -0.577\n",
            "----\n",
            "Epoch 184/300, lr=0.000833\n",
            "--> train_loss: 0.804531, test_loss: 0.853422, train_metric: -0.631, test_metric: -0.568\n",
            "----\n",
            "Epoch 185/300, lr=0.000832\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.799955, test_loss: 0.837696, train_metric: -0.631, test_metric: -0.601\n",
            "----\n",
            "Epoch 186/300, lr=0.000831\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.798407, test_loss: 0.835831, train_metric: -0.639, test_metric: -0.599\n",
            "----\n",
            "Epoch 187/300, lr=0.000830\n",
            "--> train_loss: 0.797576, test_loss: 0.846022, train_metric: -0.635, test_metric: -0.571\n",
            "----\n",
            "Epoch 188/300, lr=0.000829\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.794916, test_loss: 0.832075, train_metric: -0.642, test_metric: -0.581\n",
            "----\n",
            "Epoch 189/300, lr=0.000829\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.792282, test_loss: 0.825407, train_metric: -0.637, test_metric: -0.606\n",
            "----\n",
            "Epoch 190/300, lr=0.000828\n",
            "--> train_loss: 0.787983, test_loss: 0.827036, train_metric: -0.644, test_metric: -0.580\n",
            "----\n",
            "Epoch 191/300, lr=0.000827\n",
            "--> train_loss: 0.786598, test_loss: 0.841616, train_metric: -0.655, test_metric: -0.575\n",
            "----\n",
            "Epoch 192/300, lr=0.000826\n",
            "--> train_loss: 0.787772, test_loss: 0.839035, train_metric: -0.639, test_metric: -0.594\n",
            "----\n",
            "Epoch 193/300, lr=0.000825\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.787996, test_loss: 0.823457, train_metric: -0.637, test_metric: -0.590\n",
            "----\n",
            "Epoch 194/300, lr=0.000824\n",
            "--> train_loss: 0.779723, test_loss: 0.825789, train_metric: -0.647, test_metric: -0.618\n",
            "----\n",
            "Epoch 195/300, lr=0.000824\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.780605, test_loss: 0.822573, train_metric: -0.651, test_metric: -0.599\n",
            "----\n",
            "Epoch 196/300, lr=0.000823\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.775989, test_loss: 0.821546, train_metric: -0.654, test_metric: -0.589\n",
            "----\n",
            "Epoch 197/300, lr=0.000822\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.773997, test_loss: 0.813679, train_metric: -0.654, test_metric: -0.621\n",
            "----\n",
            "Epoch 198/300, lr=0.000821\n",
            "--> train_loss: 0.776108, test_loss: 0.824929, train_metric: -0.654, test_metric: -0.594\n",
            "----\n",
            "Epoch 199/300, lr=0.000820\n",
            "--> train_loss: 0.778684, test_loss: 0.835388, train_metric: -0.651, test_metric: -0.575\n",
            "----\n",
            "Epoch 200/300, lr=0.000819\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.774840, test_loss: 0.813388, train_metric: -0.650, test_metric: -0.596\n",
            "----\n",
            "Epoch 201/300, lr=0.000819\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.768438, test_loss: 0.803591, train_metric: -0.654, test_metric: -0.620\n",
            "----\n",
            "Epoch 202/300, lr=0.000818\n",
            "--> train_loss: 0.766587, test_loss: 0.804766, train_metric: -0.653, test_metric: -0.608\n",
            "----\n",
            "Epoch 203/300, lr=0.000817\n",
            "--> train_loss: 0.767682, test_loss: 0.809377, train_metric: -0.664, test_metric: -0.622\n",
            "----\n",
            "Epoch 204/300, lr=0.000816\n",
            "--> train_loss: 0.770443, test_loss: 0.804589, train_metric: -0.646, test_metric: -0.625\n",
            "----\n",
            "Epoch 205/300, lr=0.000815\n",
            "--> train_loss: 0.760766, test_loss: 0.807518, train_metric: -0.661, test_metric: -0.602\n",
            "----\n",
            "Epoch 206/300, lr=0.000815\n",
            "--> train_loss: 0.762526, test_loss: 0.806349, train_metric: -0.661, test_metric: -0.613\n",
            "----\n",
            "Epoch 207/300, lr=0.000814\n",
            "--> train_loss: 0.758962, test_loss: 0.807245, train_metric: -0.663, test_metric: -0.601\n",
            "----\n",
            "Epoch 208/300, lr=0.000813\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.759867, test_loss: 0.796267, train_metric: -0.657, test_metric: -0.616\n",
            "----\n",
            "Epoch 209/300, lr=0.000812\n",
            "--> train_loss: 0.753814, test_loss: 0.824174, train_metric: -0.660, test_metric: -0.618\n",
            "----\n",
            "Epoch 210/300, lr=0.000811\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.759459, test_loss: 0.789828, train_metric: -0.657, test_metric: -0.627\n",
            "----\n",
            "Epoch 211/300, lr=0.000810\n",
            "--> train_loss: 0.755355, test_loss: 0.811957, train_metric: -0.663, test_metric: -0.601\n",
            "----\n",
            "Epoch 212/300, lr=0.000810\n",
            "--> train_loss: 0.754365, test_loss: 0.798609, train_metric: -0.663, test_metric: -0.617\n",
            "----\n",
            "Epoch 213/300, lr=0.000809\n",
            "--> train_loss: 0.758164, test_loss: 0.794669, train_metric: -0.660, test_metric: -0.612\n",
            "----\n",
            "Epoch 214/300, lr=0.000808\n",
            "--> train_loss: 0.748611, test_loss: 0.790959, train_metric: -0.656, test_metric: -0.626\n",
            "----\n",
            "Epoch 215/300, lr=0.000807\n",
            "--> train_loss: 0.745895, test_loss: 0.794112, train_metric: -0.666, test_metric: -0.620\n",
            "----\n",
            "Epoch 216/300, lr=0.000806\n",
            "--> train_loss: 0.743572, test_loss: 0.796046, train_metric: -0.667, test_metric: -0.601\n",
            "----\n",
            "Epoch 217/300, lr=0.000806\n",
            "--> train_loss: 0.743541, test_loss: 0.794172, train_metric: -0.671, test_metric: -0.625\n",
            "----\n",
            "Epoch 218/300, lr=0.000805\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.739425, test_loss: 0.778076, train_metric: -0.675, test_metric: -0.626\n",
            "----\n",
            "Epoch 219/300, lr=0.000804\n",
            "--> train_loss: 0.736611, test_loss: 0.784819, train_metric: -0.673, test_metric: -0.613\n",
            "----\n",
            "Epoch 220/300, lr=0.000803\n",
            "--> train_loss: 0.738336, test_loss: 0.780501, train_metric: -0.674, test_metric: -0.633\n",
            "----\n",
            "Epoch 221/300, lr=0.000802\n",
            "--> train_loss: 0.735834, test_loss: 0.790861, train_metric: -0.671, test_metric: -0.608\n",
            "----\n",
            "Epoch 222/300, lr=0.000802\n",
            "--> train_loss: 0.733450, test_loss: 0.782527, train_metric: -0.671, test_metric: -0.625\n",
            "----\n",
            "Epoch 223/300, lr=0.000801\n",
            "--> train_loss: 0.744441, test_loss: 0.806434, train_metric: -0.657, test_metric: -0.617\n",
            "----\n",
            "Epoch 224/300, lr=0.000800\n",
            "--> train_loss: 0.733244, test_loss: 0.822234, train_metric: -0.672, test_metric: -0.596\n",
            "----\n",
            "Epoch 225/300, lr=0.000799\n",
            "--> train_loss: 0.748531, test_loss: 0.783426, train_metric: -0.663, test_metric: -0.636\n",
            "----\n",
            "Epoch 226/300, lr=0.000798\n",
            "--> train_loss: 0.738881, test_loss: 0.800464, train_metric: -0.667, test_metric: -0.607\n",
            "----\n",
            "Epoch 227/300, lr=0.000798\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.735747, test_loss: 0.769518, train_metric: -0.674, test_metric: -0.625\n",
            "----\n",
            "Epoch 228/300, lr=0.000797\n",
            "--> train_loss: 0.724459, test_loss: 0.769703, train_metric: -0.678, test_metric: -0.616\n",
            "----\n",
            "Epoch 229/300, lr=0.000796\n",
            "--> train_loss: 0.725624, test_loss: 0.784265, train_metric: -0.673, test_metric: -0.615\n",
            "----\n",
            "Epoch 230/300, lr=0.000795\n",
            "--> train_loss: 0.725278, test_loss: 0.779885, train_metric: -0.674, test_metric: -0.621\n",
            "----\n",
            "Epoch 231/300, lr=0.000794\n",
            "--> train_loss: 0.728224, test_loss: 0.771714, train_metric: -0.670, test_metric: -0.625\n",
            "----\n",
            "Epoch 232/300, lr=0.000794\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.720681, test_loss: 0.760179, train_metric: -0.677, test_metric: -0.627\n",
            "----\n",
            "Epoch 233/300, lr=0.000793\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.720642, test_loss: 0.759963, train_metric: -0.674, test_metric: -0.622\n",
            "----\n",
            "Epoch 234/300, lr=0.000792\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.717024, test_loss: 0.755121, train_metric: -0.682, test_metric: -0.629\n",
            "----\n",
            "Epoch 235/300, lr=0.000791\n",
            "--> train_loss: 0.715381, test_loss: 0.768795, train_metric: -0.682, test_metric: -0.631\n",
            "----\n",
            "Epoch 236/300, lr=0.000790\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.715313, test_loss: 0.755070, train_metric: -0.673, test_metric: -0.626\n",
            "----\n",
            "Epoch 237/300, lr=0.000790\n",
            "--> train_loss: 0.713147, test_loss: 0.763316, train_metric: -0.677, test_metric: -0.623\n",
            "----\n",
            "Epoch 238/300, lr=0.000789\n",
            "--> train_loss: 0.706165, test_loss: 0.761208, train_metric: -0.684, test_metric: -0.637\n",
            "----\n",
            "Epoch 239/300, lr=0.000788\n",
            "--> train_loss: 0.717573, test_loss: 0.768591, train_metric: -0.683, test_metric: -0.618\n",
            "----\n",
            "Epoch 240/300, lr=0.000787\n",
            "--> train_loss: 0.709885, test_loss: 0.757122, train_metric: -0.677, test_metric: -0.612\n",
            "----\n",
            "Epoch 241/300, lr=0.000787\n",
            "--> train_loss: 0.713929, test_loss: 0.758726, train_metric: -0.675, test_metric: -0.625\n",
            "----\n",
            "Epoch 242/300, lr=0.000786\n",
            "--> train_loss: 0.705523, test_loss: 0.755758, train_metric: -0.679, test_metric: -0.644\n",
            "----\n",
            "Epoch 243/300, lr=0.000785\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.707200, test_loss: 0.751539, train_metric: -0.682, test_metric: -0.634\n",
            "----\n",
            "Epoch 244/300, lr=0.000784\n",
            "--> train_loss: 0.699830, test_loss: 0.754914, train_metric: -0.685, test_metric: -0.633\n",
            "----\n",
            "Epoch 245/300, lr=0.000783\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.700359, test_loss: 0.746321, train_metric: -0.685, test_metric: -0.637\n",
            "----\n",
            "Epoch 246/300, lr=0.000783\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.702698, test_loss: 0.744790, train_metric: -0.672, test_metric: -0.634\n",
            "----\n",
            "Epoch 247/300, lr=0.000782\n",
            "--> train_loss: 0.699532, test_loss: 0.745384, train_metric: -0.689, test_metric: -0.644\n",
            "----\n",
            "Epoch 248/300, lr=0.000781\n",
            "--> train_loss: 0.693671, test_loss: 0.758099, train_metric: -0.695, test_metric: -0.617\n",
            "----\n",
            "Epoch 249/300, lr=0.000780\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.701343, test_loss: 0.737518, train_metric: -0.685, test_metric: -0.641\n",
            "----\n",
            "Epoch 250/300, lr=0.000779\n",
            "--> train_loss: 0.690350, test_loss: 0.749395, train_metric: -0.685, test_metric: -0.622\n",
            "----\n",
            "Epoch 251/300, lr=0.000779\n",
            "--> train_loss: 0.697487, test_loss: 0.752563, train_metric: -0.685, test_metric: -0.643\n",
            "----\n",
            "Epoch 252/300, lr=0.000778\n",
            "--> train_loss: 0.704931, test_loss: 0.740896, train_metric: -0.695, test_metric: -0.623\n",
            "----\n",
            "Epoch 253/300, lr=0.000777\n",
            "--> train_loss: 0.692645, test_loss: 0.741407, train_metric: -0.690, test_metric: -0.633\n",
            "----\n",
            "Epoch 254/300, lr=0.000776\n",
            "--> train_loss: 0.693487, test_loss: 0.757290, train_metric: -0.684, test_metric: -0.642\n",
            "----\n",
            "Epoch 255/300, lr=0.000776\n",
            "--> train_loss: 0.695995, test_loss: 0.741885, train_metric: -0.681, test_metric: -0.654\n",
            "----\n",
            "Epoch 256/300, lr=0.000775\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.688863, test_loss: 0.734906, train_metric: -0.691, test_metric: -0.633\n",
            "----\n",
            "Epoch 257/300, lr=0.000774\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.683555, test_loss: 0.731980, train_metric: -0.696, test_metric: -0.653\n",
            "----\n",
            "Epoch 258/300, lr=0.000773\n",
            "--> train_loss: 0.689050, test_loss: 0.751800, train_metric: -0.680, test_metric: -0.629\n",
            "----\n",
            "Epoch 259/300, lr=0.000772\n",
            "--> train_loss: 0.686154, test_loss: 0.753284, train_metric: -0.691, test_metric: -0.638\n",
            "----\n",
            "Epoch 260/300, lr=0.000772\n",
            "--> train_loss: 0.680424, test_loss: 0.734434, train_metric: -0.694, test_metric: -0.643\n",
            "----\n",
            "Epoch 261/300, lr=0.000771\n",
            "--> train_loss: 0.681010, test_loss: 0.749177, train_metric: -0.698, test_metric: -0.632\n",
            "----\n",
            "Epoch 262/300, lr=0.000770\n",
            "--> train_loss: 0.691336, test_loss: 0.742003, train_metric: -0.677, test_metric: -0.652\n",
            "----\n",
            "Epoch 263/300, lr=0.000769\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.680580, test_loss: 0.728948, train_metric: -0.691, test_metric: -0.643\n",
            "----\n",
            "Epoch 264/300, lr=0.000769\n",
            "--> train_loss: 0.677224, test_loss: 0.734615, train_metric: -0.705, test_metric: -0.639\n",
            "----\n",
            "Epoch 265/300, lr=0.000768\n",
            "--> train_loss: 0.675302, test_loss: 0.739882, train_metric: -0.702, test_metric: -0.627\n",
            "----\n",
            "Epoch 266/300, lr=0.000767\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.673422, test_loss: 0.721987, train_metric: -0.695, test_metric: -0.656\n",
            "----\n",
            "Epoch 267/300, lr=0.000766\n",
            "--> train_loss: 0.671867, test_loss: 0.733569, train_metric: -0.701, test_metric: -0.653\n",
            "----\n",
            "Epoch 268/300, lr=0.000766\n",
            "--> train_loss: 0.676237, test_loss: 0.728106, train_metric: -0.700, test_metric: -0.649\n",
            "----\n",
            "Epoch 269/300, lr=0.000765\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.670144, test_loss: 0.718998, train_metric: -0.700, test_metric: -0.642\n",
            "----\n",
            "Epoch 270/300, lr=0.000764\n",
            "--> train_loss: 0.665448, test_loss: 0.726786, train_metric: -0.708, test_metric: -0.646\n",
            "----\n",
            "Epoch 271/300, lr=0.000763\n",
            "--> train_loss: 0.670079, test_loss: 0.721153, train_metric: -0.702, test_metric: -0.652\n",
            "----\n",
            "Epoch 272/300, lr=0.000763\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.668154, test_loss: 0.716253, train_metric: -0.709, test_metric: -0.639\n",
            "----\n",
            "Epoch 273/300, lr=0.000762\n",
            "--> train_loss: 0.661235, test_loss: 0.725953, train_metric: -0.706, test_metric: -0.634\n",
            "----\n",
            "Epoch 274/300, lr=0.000761\n",
            "--> train_loss: 0.666952, test_loss: 0.726717, train_metric: -0.701, test_metric: -0.646\n",
            "----\n",
            "Epoch 275/300, lr=0.000760\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.665259, test_loss: 0.714390, train_metric: -0.703, test_metric: -0.644\n",
            "----\n",
            "Epoch 276/300, lr=0.000759\n",
            "--> train_loss: 0.663838, test_loss: 0.726352, train_metric: -0.706, test_metric: -0.644\n",
            "----\n",
            "Epoch 277/300, lr=0.000759\n",
            "--> train_loss: 0.664397, test_loss: 0.735406, train_metric: -0.699, test_metric: -0.639\n",
            "----\n",
            "Epoch 278/300, lr=0.000758\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.663588, test_loss: 0.713765, train_metric: -0.705, test_metric: -0.653\n",
            "----\n",
            "Epoch 279/300, lr=0.000757\n",
            "--> train_loss: 0.662267, test_loss: 0.717651, train_metric: -0.707, test_metric: -0.660\n",
            "----\n",
            "Epoch 280/300, lr=0.000756\n",
            "--> train_loss: 0.658792, test_loss: 0.729172, train_metric: -0.706, test_metric: -0.641\n",
            "----\n",
            "Epoch 281/300, lr=0.000756\n",
            "--> train_loss: 0.665349, test_loss: 0.721972, train_metric: -0.698, test_metric: -0.658\n",
            "----\n",
            "Epoch 282/300, lr=0.000755\n",
            "--> train_loss: 0.664528, test_loss: 0.718548, train_metric: -0.700, test_metric: -0.659\n",
            "----\n",
            "Epoch 283/300, lr=0.000754\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.655347, test_loss: 0.708948, train_metric: -0.709, test_metric: -0.657\n",
            "----\n",
            "Epoch 284/300, lr=0.000753\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.660141, test_loss: 0.704673, train_metric: -0.698, test_metric: -0.657\n",
            "----\n",
            "Epoch 285/300, lr=0.000753\n",
            "--> train_loss: 0.652248, test_loss: 0.710778, train_metric: -0.714, test_metric: -0.651\n",
            "----\n",
            "Epoch 286/300, lr=0.000752\n",
            "--> train_loss: 0.652065, test_loss: 0.713229, train_metric: -0.705, test_metric: -0.652\n",
            "----\n",
            "Epoch 287/300, lr=0.000751\n",
            "--> train_loss: 0.660158, test_loss: 0.711491, train_metric: -0.705, test_metric: -0.669\n",
            "----\n",
            "Epoch 288/300, lr=0.000750\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.653920, test_loss: 0.704666, train_metric: -0.704, test_metric: -0.653\n",
            "----\n",
            "Epoch 289/300, lr=0.000750\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.645113, test_loss: 0.698304, train_metric: -0.719, test_metric: -0.643\n",
            "----\n",
            "Epoch 290/300, lr=0.000749\n",
            "--> train_loss: 0.645312, test_loss: 0.701733, train_metric: -0.713, test_metric: -0.667\n",
            "----\n",
            "Epoch 291/300, lr=0.000748\n",
            "--> train_loss: 0.644317, test_loss: 0.702682, train_metric: -0.715, test_metric: -0.657\n",
            "----\n",
            "Epoch 292/300, lr=0.000747\n",
            "--> train_loss: 0.642788, test_loss: 0.702016, train_metric: -0.709, test_metric: -0.656\n",
            "----\n",
            "Epoch 293/300, lr=0.000747\n",
            "--> train_loss: 0.647552, test_loss: 0.717239, train_metric: -0.708, test_metric: -0.654\n",
            "----\n",
            "Epoch 294/300, lr=0.000746\n",
            "--> train_loss: 0.647370, test_loss: 0.709369, train_metric: -0.708, test_metric: -0.654\n",
            "----\n",
            "Epoch 295/300, lr=0.000745\n",
            "--> train_loss: 0.648026, test_loss: 0.701824, train_metric: -0.712, test_metric: -0.652\n",
            "----\n",
            "Epoch 296/300, lr=0.000744\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.641471, test_loss: 0.695145, train_metric: -0.719, test_metric: -0.660\n",
            "----\n",
            "Epoch 297/300, lr=0.000744\n",
            "--> train_loss: 0.637625, test_loss: 0.699605, train_metric: -0.714, test_metric: -0.673\n",
            "----\n",
            "Epoch 298/300, lr=0.000743\n",
            "--> model improved! --> saved to ./weights_classification.pt\n",
            "--> train_loss: 0.641112, test_loss: 0.693360, train_metric: -0.710, test_metric: -0.663\n",
            "----\n",
            "Epoch 299/300, lr=0.000742\n",
            "--> train_loss: 0.644490, test_loss: 0.696864, train_metric: -0.710, test_metric: -0.662\n",
            "----\n",
            "Epoch 300/300, lr=0.000741\n",
            "--> train_loss: 0.643866, test_loss: 0.707218, train_metric: -0.707, test_metric: -0.642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh5CkI36nq2S"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd8jW5pynyCK",
        "outputId": "67852cf2-901b-4929-dfe2-2fc7cb947cd4"
      },
      "source": [
        "# Load Classification\n",
        "names = list({\"bianca\":0,\"gialla\": 1, \"arancione\": 2, \"rossa\": 3})\n",
        "model = ClassificationNet(num_inputs=10,num_classes=4).to(device)\n",
        "weights = torch.load(\"weights_classification.pt\")\n",
        "model.load_state_dict(weights)\n",
        "model = model.to(device)\n",
        "\n",
        "# Predict Classication\n",
        "# C_mean, C_std = 186785.728337672 679353.7516865473\n",
        "Xt = torch.from_numpy(X_test).type(torch.float32).unsqueeze(1)\n",
        "Xt = (Xt - C_mean) / C_std\n",
        "Y_hat = model.forward(Xt).argmax(dim=-1,keepdim=True).detach().numpy().reshape(-1)\n",
        "\n",
        "# Visualize results\n",
        "cm = confusion_matrix(Y_test,Y_hat)\n",
        "names_pred = [ \"Pred: \" + n for n in names]\n",
        "df = pd.DataFrame(cm, columns=names_pred, index=names)\n",
        "print(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Pred: bianca  Pred: gialla  Pred: arancione  Pred: rossa\n",
            "bianca                3             0                3            0\n",
            "gialla                8           212               53           27\n",
            "arancione             0            60              240           33\n",
            "rossa                 0            51               37           80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzgtzyhoSjJk"
      },
      "source": [
        "## Extra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qiaz_2DYhrf"
      },
      "source": [
        "\n",
        "# df.head() # prime 5 righe\n",
        "# df.tail() # ultime 5 righe\n",
        "# df.to_csv(\"a.csv\") # Salva come csv\n",
        "# df.keys() # nomi delle colonne\n",
        "# df.values.shape # dimensione\n",
        "# df.values # dati come array \n",
        "\n",
        "# Nomi delle colonne\n",
        "# Numero di righe\n",
        "# selezionare solo la colonna con nome dimessi_guariti\n",
        "# voglio i dati come array\n",
        "# voglio i deceduti > 700\n",
        "# dati del 12 marzo in poi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3OuqOczPcDe",
        "outputId": "2ac2262d-7181-4924-9e2c-e886c988b46f"
      },
      "source": [
        "x = np.array( [5,3,5,6,7] , dtype=np.float32)\n",
        "x = x.reshape(1,-1)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5., 3., 5., 6., 7.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScIeiTlAOixF",
        "outputId": "1bef673e-a10a-46c9-a6b3-3f6573b87d70"
      },
      "source": [
        "x = torch.tensor( [5,3,5,6,7] , dtype=torch.float32)\n",
        "#x = x.reshape(1,-1)\n",
        "#x = x.unsqueeze(0)\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zi77p6zQ9V8",
        "outputId": "e16d4c9e-a60a-452e-8e73-eda3e02e123c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "d = {\n",
        "    \"c\" : [5,6,7,8,9],\n",
        "    \"e\" : [15,26,37,18,29],\n",
        "    \"t\" : [0.5,0.26,3.7,1.8,29], \n",
        "}\n",
        "\n",
        "df = pd.DataFrame(d)\n",
        "df.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.  , 15.  ,  0.5 ],\n",
              "       [ 6.  , 26.  ,  0.26],\n",
              "       [ 7.  , 37.  ,  3.7 ],\n",
              "       [ 8.  , 18.  ,  1.8 ],\n",
              "       [ 9.  , 29.  , 29.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gACjphVQRmfr",
        "outputId": "ab8c298d-ea14-4b5d-e55c-2b422e4eaf88"
      },
      "source": [
        "x = torch.from_numpy(df.values).type(torch.float32)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.0000, 15.0000,  0.5000],\n",
              "        [ 6.0000, 26.0000,  0.2600],\n",
              "        [ 7.0000, 37.0000,  3.7000],\n",
              "        [ 8.0000, 18.0000,  1.8000],\n",
              "        [ 9.0000, 29.0000, 29.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pK5HYRjSNaS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}