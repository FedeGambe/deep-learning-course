{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClassificationSimple.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visiont3lab/deep-learning-course/blob/main/colab/ClassificationSimple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ki_9emN-Nh"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb5e5v7Hg-RA"
      },
      "source": [
        "* [Softmax](https://machinelearningmastery.com/softmax-activation-function-with-python/#:~:text=Softmax%20is%20a%20mathematical%20function,each%20value%20in%20the%20vector.&text=Each%20value%20in%20the%20output,of%20membership%20for%20each%20class.)\n",
        "[math Softmax](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/)\n",
        "* [Pytorch training](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrh2RbiWNw2A"
      },
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "#!pip install torchsummary\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset,Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "# Loss function pytorch: https://neptune.ai/blog/pytorch-loss-functions\n",
        "import copy\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l18NVUALSl3M"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USTBnGioKlaC"
      },
      "source": [
        "#!pip install pandas\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/visiont3lab/deep-learning-course/main/data/covid19-ita-regioni.csv\")\n",
        "df.to_csv(\"kldskd.csv\")\n",
        "\n",
        "lx = [\"terapia_intensiva\",\"isolamento_domiciliare\",\"totale_positivi\",\"dimessi_guariti\",\"deceduti\",\"tamponi\",\"indice_rt\"]\n",
        "ly = [\"zona\"]\n",
        "X = df[lx].values\n",
        "Y = df[ly].values\n",
        "\n",
        "a = {\n",
        "    \"bianca\": 0,\n",
        "    \"gialla\": 1,\n",
        "    \"arancione\": 2,\n",
        "    \"rossa\": 3,\n",
        "}\n",
        "\n",
        "Y = []\n",
        "for el in df[\"zona\"].tolist():\n",
        "  Y.append( a[el] )\n",
        "\n",
        "Y = [a[el] for el in df[\"zona\"].tolist()]\n",
        "Y = np.array(Y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNKMEKUeMhYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22af6f99-4eaa-4277-d9f4-1792fd1b2cc9"
      },
      "source": [
        "set(df[\"zona\"].tolist())\n",
        "df[\"zona\"].unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['arancione', 'rossa', 'gialla', 'bianca'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbo5O0hSTC-0"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EobOBkZFOXa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14dc4a23-9c5e-44d2-f165-96b1ed052323"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Training and Test Set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,shuffle=True,random_state=2)\n",
        "print(f\"X Train shape: {X_train.shape} , X Test shape: {X_test.shape}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train shape: (1882, 7) , X Test shape: (807, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvJSOydmOkvb"
      },
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class MyDatasets(Dataset):\n",
        "  def __init__(self,x,y):\n",
        "    self.x = torch.tensor(x,dtype=torch.float32)\n",
        "    #self.x = (self.x - torch.mean(self.x) ) / torch.std(self.x)\n",
        "    self.y = torch.tensor(y,dtype=torch.int64) \n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index], self.y[index]\n",
        "  def __len__(self):\n",
        "    #print(self.y.shape[0])\n",
        "    return self.y.shape[0]\n",
        "\n",
        "# Load training data\n",
        "train_ds = MyDatasets(X_train,Y_train)\n",
        "train_dl = DataLoader(train_ds,batch_size=10,shuffle=True)\n",
        "\n",
        "# Load test data\n",
        "test_ds = MyDatasets(X_test,Y_test)\n",
        "test_dl = DataLoader(test_ds,batch_size=10,shuffle=True)\n",
        "\n",
        "#ds.__getitem__(1)\n",
        "#for x,y in train_dl:\n",
        "#  print(x,y)\n",
        "#  break"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4yFxS_Id-LN"
      },
      "source": [
        "## Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxQLV6mhFbel",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "24fa5cf7-dbca-4f48-8dd7-fe5d31ba5ba1"
      },
      "source": [
        "'''\n",
        "# Softmax\n",
        "y = torch.log_softmax( torch.tensor( [1,6,3], dtype=torch.float32), dim=0 ) \n",
        "y1 = torch.softmax( torch.tensor( [1,6,3], dtype=torch.float32), dim=0 ) \n",
        "\n",
        "print(y)\n",
        "print(y1)\n",
        "\n",
        "p1 = np.log( np.exp(1)/ ( np.exp(1)+np.exp(2)+np.exp(3) ) )\n",
        "p2 = np.log( np.exp(2)/ ( np.exp(1)+np.exp(2)+np.exp(3) ) )\n",
        "p3 = np.log( np.exp(3)/ ( np.exp(1)+np.exp(2)+np.exp(3) ) )\n",
        "\n",
        "print(np.round(p1,4),np.round(p2,4),np.round(p3,4))\n",
        "\n",
        "torch.argmax( y )\n",
        "torch.argmax( y1 )\n",
        "'''"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Softmax\\ny = torch.log_softmax( torch.tensor( [1,6,3], dtype=torch.float32), dim=0 ) \\ny1 = torch.softmax( torch.tensor( [1,6,3], dtype=torch.float32), dim=0 ) \\n\\nprint(y)\\nprint(y1)\\n\\np1 = np.log( np.exp(1)/ ( np.exp(1)+np.exp(2)+np.exp(3) ) )\\np2 = np.log( np.exp(2)/ ( np.exp(1)+np.exp(2)+np.exp(3) ) )\\np3 = np.log( np.exp(3)/ ( np.exp(1)+np.exp(2)+np.exp(3) ) )\\n\\nprint(np.round(p1,4),np.round(p2,4),np.round(p3,4))\\n\\ntorch.argmax( y )\\ntorch.argmax( y1 )\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W1jPA8a_IvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecaaccc3-b1eb-4d18-a8ca-0c2b92226ab9"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "# rete 7 input , 100 neuroni (primo hidden layer), 50 neuroni (secondo hidden layer, 4 neuroni nell'ouput layer)\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNet,self).__init__()\n",
        "    num_inputs = 7\n",
        "    num_outputs = 4\n",
        "    self.fc1 = nn.Linear(7,100) \n",
        "    self.fc2 = nn.Linear(100,50) \n",
        "    self.fc3 = nn.Linear(50,4) \n",
        "  def forward(self,x):\n",
        "    x = torch.tanh( self.fc1(x) )\n",
        "    x = torch.tanh( self.fc2(x) )\n",
        "    x = torch.tanh( self.fc3(x) )\n",
        "    x = torch.log_softmax( x, dim=-1 ) #NNLL\n",
        "    return x\n",
        "\n",
        "model = NeuralNet()\n",
        "\n",
        "# Visualiza parameters\n",
        "#for name, param in model.named_parameters():\n",
        "#  print(name,param)\n",
        "\n",
        "#inp = torch.tensor([5,5],dtype=torch.float32)\n",
        "#y = model.forward(inp)\n",
        "#print(y)\n",
        "#torch.argmax(y)\n",
        "\n",
        "# Test\n",
        "fake_input = torch.randn((1,7))\n",
        "y_hat = model(fake_input)\n",
        "print(y_hat)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.3026, -1.5162, -1.3723, -1.3660]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSKvlZJdVGaZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuCfZImQVHps",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b1fc0dd-ef55-4217-9ded-c4cf7a025772"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Inizilizzo il modello\n",
        "model = NeuralNet()\n",
        "\n",
        "# Definiscoo la loss\n",
        "criterion = torch.nn.NLLLoss(reduction=\"sum\")\n",
        "\n",
        "# Definisco l'optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "\n",
        "    # Training su tutto il dataset\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dl, 0):\n",
        "       \n",
        "        # prendo i dati (a gruppi batch size)\n",
        "        inputs, labels = data\n",
        "        #print(inputs, labels)\n",
        "      \n",
        "        # zero the parameter gradients (resetto i pesi )\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward (trovo i valori stimati )\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Mi calcolo l'errore\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # back propagation (trovare la derivata dell loss function)\n",
        "        loss.backward()\n",
        "\n",
        "        # aggiorna i pesi\n",
        "        optimizer.step()\n",
        "\n",
        "        # stampi la loss attuale\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Alla fine di un aggiornamente --> Quanto è buono il mio modello?\n",
        "        total_corrects = 0\n",
        "        for xtest,ytest in test_dl:\n",
        "          ytest_hat = torch.argmax( model(xtest) , dim=-1, keepdim=True )\n",
        "          corrects = ytest_hat.eq(ytest.reshape(ytest_hat.shape)).sum().item()\n",
        "          total_corrects = total_corrects + corrects\n",
        "\n",
        "        print(f\"corretti: %s/%s\" % (str(total_corrects),str(len(test_dl))))\n",
        "        \n",
        "    print(f\"Epoca: %s --> Loss: %s\" % (str(epoch),str(np.round(running_loss,3))))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corretti: 300/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "Epoca: 0 --> Loss: 2165.784\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 300/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n",
            "corretti: 333/81\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8341f0db3d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtotal_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m           \u001b[0mytest_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m           \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mytest_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mtotal_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_corrects\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcorrects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pK5HYRjSNaS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}