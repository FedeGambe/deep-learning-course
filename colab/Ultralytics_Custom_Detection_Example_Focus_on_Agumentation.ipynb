{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ultralytics Oriented bouding box"
      ],
      "metadata": {
        "id": "6NwwliogBETy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up runtime to use GPU"
      ],
      "metadata": {
        "id": "xK_eUvfjBI8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "OFAPoqVclm5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look for dataset"
      ],
      "metadata": {
        "id": "MjQ_B2F_tUfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Roboflow Universe](https://universe.roboflow.com/)\n",
        "* [Google dataset](https://datasetsearch.research.google.com/?hl=it)\n",
        "* [Kaggle dataset](https://www.kaggle.com/datasets?fileType=csv)\n",
        "* [Halcon MVTecIndustrial dataset](https://www.mvtec.com/company/research/datasets/mvtec-ad/downloads)"
      ],
      "metadata": {
        "id": "a5UERHbkkEV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "sy0R5TaujzyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import random\n",
        "import albumentations as A\n",
        "from ultralytics import YOLO\n",
        "import json\n",
        "import yaml\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "f8QmOEm9m1Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
        "    # initialize the dimensions of the image to be resized and\n",
        "    # grab the image size\n",
        "    dim = None\n",
        "    (h, w) = image.shape[:2]\n",
        "\n",
        "    # if both the width and height are None, then return the\n",
        "    # original image\n",
        "    if width is None and height is None:\n",
        "        return image\n",
        "\n",
        "    # check to see if the width is None\n",
        "    if width is None:\n",
        "        # calculate the ratio of the height and construct the\n",
        "        # dimensions\n",
        "        r = height / float(h)\n",
        "        dim = (int(w * r), height)\n",
        "\n",
        "    # otherwise, the height is None\n",
        "    else:\n",
        "        # calculate the ratio of the width and construct the\n",
        "        # dimensions\n",
        "        r = width / float(w)\n",
        "        dim = (width, int(h * r))\n",
        "\n",
        "    # resize the image\n",
        "    resized = cv2.resize(image, dim, interpolation=inter)\n",
        "\n",
        "    # return the resized image\n",
        "    return resized\n",
        "\n",
        "def convert_yolo_to_albumentations(normalized_coords_yolo):\n",
        "    \"\"\"\n",
        "        normalized_coords Nx4 list\n",
        "        yolo          --> normalize[x_center, y_center, width, height]\n",
        "        albumentation --> normalize[x_min, y_min, x_max, y_max]\n",
        "    \"\"\"\n",
        "\n",
        "    normalized_coords_alb = []\n",
        "    for normalized_coord in normalized_coords_yolo:\n",
        "        x_center, y_center, width, height = normalized_coord\n",
        "\n",
        "        x_min = x_center - (width / 2)\n",
        "        y_min = y_center - (height / 2)\n",
        "        x_max = x_center + (width / 2)\n",
        "        y_max = y_center + (height / 2)\n",
        "\n",
        "        normalized_coords_alb.append([x_min,y_min, x_max, y_max])\n",
        "\n",
        "    return normalized_coords_alb\n",
        "\n",
        "def convert_yolo_box_to_absolute(normalized_coords, image_width, image_height):\n",
        "    \"\"\"\n",
        "    Convert normalized YOLO coordinates to absolute pixel coordinates.\n",
        "\n",
        "    Args:\n",
        "    - normalized_coords (tuple): A tuple of (x_center, y_center, width, height) in normalized format.\n",
        "    - image_width (int): The width of the image.\n",
        "    - image_height (int): The height of the image.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: A tuple of (x_min, y_min, x_max, y_max) in absolute pixel coordinates.\n",
        "    \"\"\"\n",
        "    x_center, y_center, width, height = normalized_coords\n",
        "    x_center_abs = x_center * image_width\n",
        "    y_center_abs = y_center * image_height\n",
        "    width_abs = width * image_width\n",
        "    height_abs = height * image_height\n",
        "\n",
        "    x_min = x_center_abs - (width_abs / 2)\n",
        "    y_min = y_center_abs - (height_abs / 2)\n",
        "    x_max = x_center_abs + (width_abs / 2)\n",
        "    y_max = y_center_abs + (height_abs / 2)\n",
        "\n",
        "    x_min = int(x_min)\n",
        "    y_min = int(y_min)\n",
        "    x_max = int(x_max)\n",
        "    y_max = int(y_max)\n",
        "\n",
        "    return (x_min, y_min, x_max, y_max)\n",
        "\n",
        "def convert_yolo_poly_to_absolute(normalized_coords, image_width, image_height):\n",
        "    \"\"\"\n",
        "    Convert normalized YOLO coordinates to absolute pixel coordinates.\n",
        "\n",
        "    Args:\n",
        "    - normalized_coords (tuple): A tuple of (x_center, y_center, width, height) in normalized format.\n",
        "    - image_width (int): The width of the image.\n",
        "    - image_height (int): The height of the image.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: A tuple of (x_min, y_min, x_max, y_max) in absolute pixel coordinates.\n",
        "    \"\"\"\n",
        "    n = len(normalized_coords)//2\n",
        "    cnt = np.array(normalized_coords).reshape(n,-1)\n",
        "    cnt[:,0] = cnt[:,0]*image_width\n",
        "    cnt[:,1] = cnt[:,1]*image_height\n",
        "    cnt = cnt.astype(int)\n",
        "    return cnt\n",
        "\n",
        "def load_yolov8_det_labels(file_path):\n",
        "    \"\"\"\n",
        "    Load yolov8 box coordinate\n",
        "    \"\"\"\n",
        "    labels = []\n",
        "    boxes = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # Each line is expected to be 'class_id x_center y_center width height'\n",
        "            class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "            boxes.append([x_center, y_center, width, height])\n",
        "            labels.append(int(class_id))\n",
        "    return boxes, labels\n",
        "\n",
        "def load_yolov8_seg_labels(file_path):\n",
        "    \"\"\"\n",
        "    Load yolov8 polylines\n",
        "    \"\"\"\n",
        "    labels = []\n",
        "    boxes = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            # Each line is expected to be 'class_id x_center y_center width height'\n",
        "            #class_id, x_center, y_center, width, height = map(float, line.split())\n",
        "            #boxes.append([x_center, y_center, width, height])\n",
        "            l = list(map(float, line.split()))\n",
        "            class_id = l[0]\n",
        "            poly = l[1:]\n",
        "            boxes.append(poly)\n",
        "            labels.append(int(class_id))\n",
        "    return boxes, labels\n",
        "\n",
        "def load_yolov8_labels_name(file_path):\n",
        "    #file_path = f\"{folder_dataset}/notes.json\"\n",
        "    f = open(file_path)\n",
        "    info_data = json.load(f)\n",
        "    labels_name = [info_data[\"categories\"][i][\"name\"] for i in range(0,len(info_data[\"categories\"]))]\n",
        "    return labels_name\n",
        "\n",
        "def augment_seg(img, keypoints_yolo, class_labels, transform):\n",
        "\n",
        "    img_height = img.shape[0]\n",
        "    img_width = img.shape[1]\n",
        "\n",
        "    # Boxes yolo to absoltute coordinate:\n",
        "    keypoints_alb = []\n",
        "    class_labes_alb = []\n",
        "    k=0\n",
        "    for keypoint_raw ,label in zip(keypoints_yolo, class_labels):\n",
        "        cnt = convert_yolo_poly_to_absolute(keypoint_raw, img_width, img_height)\n",
        "        cnt[:,0] = np.clip(cnt[:,0], 0, img_width-1)\n",
        "        cnt[:,1] = np.clip(cnt[:,1], 0, img_height-1)\n",
        "        cnt = [tuple(row) for row in cnt]\n",
        "        keypoints_alb.extend(cnt)\n",
        "        for i in range(0, len(cnt)):\n",
        "            class_labes_alb.append(f\"{label}_{k}\")\n",
        "        k = k+1\n",
        "\n",
        "    tr = transform(image=img, keypoints=keypoints_alb, class_labels=class_labes_alb)\n",
        "    tr_img = tr['image']\n",
        "    tr_bboxes_yolo = tr['keypoints']\n",
        "    tr_class_labels = tr['class_labels']\n",
        "\n",
        "    tr_img_debug = tr_img.copy()\n",
        "\n",
        "    # Ricostruzione:\n",
        "    aug_keypoints = []\n",
        "    aug_class_labels = []\n",
        "    unique_elements = list(set(tr_class_labels))\n",
        "    tmp_label = np.array(tr_class_labels)\n",
        "    tmp_cnt = np.array(tr_bboxes_yolo)\n",
        "    for label in unique_elements:\n",
        "        idx = np.where(tmp_label == label)[0]\n",
        "        cnt = tmp_cnt[idx].astype(float)\n",
        "\n",
        "        cnt_norm = cnt\n",
        "        cnt_norm[:,0] = cnt_norm[:,0]/img_width\n",
        "        cnt_norm[:,1] = cnt_norm[:,1]/img_height\n",
        "        cnt_norm = cnt_norm.reshape(-1)\n",
        "\n",
        "        label = label.split(\"_\")[0]\n",
        "\n",
        "        cnt = tmp_cnt[idx].astype(int)\n",
        "        cv2.drawContours(tr_img_debug, [cnt], -1, (255, 0, 0), 1)\n",
        "        M = cv2.moments(cnt)\n",
        "        if  M[\"m00\"]!=0:\n",
        "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "            cv2.putText(tr_img_debug, f\"{label} \", (cx, cy -10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "        aug_keypoints.append(cnt_norm)\n",
        "        aug_class_labels.append(label)\n",
        "\n",
        "    return tr_img, aug_keypoints, aug_class_labels, tr_img_debug\n",
        "\n",
        "def augment_yolov8_seg(transform, folder_inp_images, folder_inp_labels, folder_out_images_aug, folder_out_labels_aug, labels_name, folder_out_images_aug_check):\n",
        "\n",
        "    # Save images augmented\n",
        "    folder_images_aug = folder_out_images_aug\n",
        "    folder_labels_aug = folder_out_labels_aug\n",
        "    if os.path.exists(folder_images_aug):\n",
        "        shutil.rmtree(folder_images_aug)\n",
        "    os.makedirs(folder_images_aug)\n",
        "    if os.path.exists(folder_labels_aug):\n",
        "        shutil.rmtree(folder_labels_aug)\n",
        "    os.makedirs(folder_labels_aug)\n",
        "    if os.path.exists(folder_out_images_aug_check):\n",
        "        shutil.rmtree(folder_out_images_aug_check)\n",
        "    os.makedirs(folder_out_images_aug_check)\n",
        "\n",
        "    # Augmentation\n",
        "    folder_images = folder_inp_images\n",
        "    folder_labels = folder_inp_labels\n",
        "\n",
        "    # pascal_voc --> x_min, y_min, x_max, y_max\n",
        "    # coco --> x_min, ymin, width, height\n",
        "    # albumentation --> normalize[x_min, y_min, x_max, y_max]\n",
        "    # yolo --> normalize[x_center, y_center, width, height]\n",
        "    #f = open(f\"{folder_labelstudio}/notes.json\")\n",
        "    #info_data = json.load(f)\n",
        "    # labels_name = [info_data[\"categories\"][i][\"name\"] for i in range(0,len(info_data[\"categories\"]))]\n",
        "\n",
        "    N = 2\n",
        "    for i in range(0, N):\n",
        "        filenames = []\n",
        "        for name in tqdm(os.listdir(folder_images)):\n",
        "            ext = name.split(\".\")[-1]\n",
        "            basename = name.split(\".\")[-2]\n",
        "            img_pil = Image.open(os.path.join(folder_images, name)).convert(\"RGB\")\n",
        "            img = np.array(img_pil)\n",
        "            label_path = os.path.join(folder_labels, name.replace(ext,\"txt\"))\n",
        "            keypoints_yolo, class_ids = load_yolov8_seg_labels(label_path)\n",
        "            class_labels = [labels_name[class_id] for class_id in class_ids]\n",
        "\n",
        "            # Augmentation\n",
        "            if transform is None:\n",
        "                tr = transform(image=img)\n",
        "                aug_img = tr['image']\n",
        "                aug_keypoints = keypoints_yolo\n",
        "                aug_class_labels = class_labels\n",
        "                aug_img_debug = aug_img.copy()\n",
        "                for keypoint_raw ,label in zip(keypoints_yolo, class_labels):\n",
        "                    cnt = convert_yolo_poly_to_absolute(keypoint_raw, img_pil.width, img_pil.height)\n",
        "                    cv2.drawContours(aug_img_debug, [cnt], -1, (255, 0, 0), 1)\n",
        "                    M = cv2.moments(cnt)\n",
        "                    if M[\"m00\"] !=0:\n",
        "                        cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                        cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "                        cv2.putText(aug_img_debug, f\"{label} \", (cx, cy -10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "            else:\n",
        "                aug_img, aug_keypoints, aug_class_labels, aug_img_debug = augment_seg(img, keypoints_yolo, class_labels, transform)\n",
        "\n",
        "\n",
        "            # Alway check augmentation\n",
        "            if True:\n",
        "                filepath_image_save = f\"{folder_out_images_aug_check}/{i}_{basename}.png\"\n",
        "                tmp_aug_img_pil = Image.fromarray(aug_img_debug)\n",
        "                tmp_aug_img_pil.save(filepath_image_save)\n",
        "\n",
        "\n",
        "            filepath_label_save = f\"{folder_labels_aug}/{i}_{basename}.txt\"\n",
        "            with open(filepath_label_save, 'w') as file:\n",
        "                # Save new images and labels\n",
        "                for box_yolo, class_label in zip(aug_keypoints, aug_class_labels):\n",
        "                    class_id = labels_name.index(class_label)\n",
        "                    #x_center, y_center, width, height = box_yolo\n",
        "                    #file.write(f\"{class_id} {x_center} {y_center} {width} {height} \\n\")\n",
        "                    file.write(f\"{class_id} {' '.join(map(str,box_yolo))} \\n\")\n",
        "\n",
        "            filepath_image_save = f\"{folder_images_aug}/{i}_{basename}.png\"\n",
        "            tr_img_pil = Image.fromarray(aug_img)\n",
        "            tr_img_pil.save(filepath_image_save)\n",
        "            #break\n",
        "\n",
        "def augment_yolov8_det(transform, folder_inp_images, folder_inp_labels, folder_out_images_aug, folder_out_labels_aug, labels_name, folder_out_images_aug_check):\n",
        "\n",
        "    # Save images augmented\n",
        "    folder_images_aug = folder_out_images_aug\n",
        "    folder_labels_aug = folder_out_labels_aug\n",
        "    if os.path.exists(folder_images_aug):\n",
        "        shutil.rmtree(folder_images_aug)\n",
        "    os.makedirs(folder_images_aug)\n",
        "    if os.path.exists(folder_labels_aug):\n",
        "        shutil.rmtree(folder_labels_aug)\n",
        "    os.makedirs(folder_labels_aug)\n",
        "    if os.path.exists(folder_out_images_aug_check):\n",
        "        shutil.rmtree(folder_out_images_aug_check)\n",
        "    os.makedirs(folder_out_images_aug_check)\n",
        "\n",
        "    # Augmentation\n",
        "    folder_images = folder_inp_images\n",
        "    folder_labels = folder_inp_labels\n",
        "\n",
        "    # pascal_voc --> x_min, y_min, x_max, y_max\n",
        "    # coco --> x_min, ymin, width, height\n",
        "    # albumentation --> normalize[x_min, y_min, x_max, y_max]\n",
        "    # yolo --> normalize[x_center, y_center, width, height]\n",
        "    #f = open(f\"{folder_labelstudio}/notes.json\")\n",
        "    #info_data = json.load(f)\n",
        "    # labels_name = [info_data[\"categories\"][i][\"name\"] for i in range(0,len(info_data[\"categories\"]))]\n",
        "\n",
        "    print(f\"Labels: {labels_name}\")\n",
        "\n",
        "    N = 2\n",
        "    for i in range(0, N):\n",
        "        filenames = []\n",
        "        for name in tqdm(os.listdir(folder_images)):\n",
        "            ext = name.split(\".\")[-1]\n",
        "            basename = name.split(\".\")[-2]\n",
        "            img = Image.open(os.path.join(folder_images, name)).convert(\"RGB\")\n",
        "            img = np.array(img)\n",
        "            label_path = os.path.join(folder_labels, name.replace(ext,\"txt\"))\n",
        "            boxes_yolo, class_ids = load_yolov8_det_labels(label_path)\n",
        "            class_labels = [labels_name[class_id] for class_id in class_ids]\n",
        "\n",
        "            #boxes_alb = convert_format_yolo_to_albumentations(boxes_yolo)\n",
        "\n",
        "            #tr_img = img\n",
        "            #tr_bboxes_yolo = boxes_yolo\n",
        "            #tr_class_labels = class_labels\n",
        "\n",
        "            #if i>0:\n",
        "            # DOCS: https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/\n",
        "            if transform is None:\n",
        "                tr_img = img\n",
        "                tr_bboxes_yolo = boxes_yolo\n",
        "                tr_class_labels = class_labels\n",
        "            else:\n",
        "                tr = transform(image=img, bboxes=boxes_yolo, class_labels=class_labels)\n",
        "                tr_img = tr['image']\n",
        "                tr_bboxes_yolo = tr['bboxes']\n",
        "                tr_class_labels = tr['class_labels']\n",
        "\n",
        "\n",
        "            # Check augmentation\n",
        "            im_draw = np.array(tr_img.copy())\n",
        "            for box_yolo, class_label in zip(tr_bboxes_yolo, tr_class_labels):\n",
        "                # Draw\n",
        "                x_center, y_center, width, height = box_yolo\n",
        "                normalized_coords = [x_center, y_center, width, height]\n",
        "                x_min, y_min, x_max, y_max = convert_yolo_box_to_absolute(normalized_coords, img.shape[1], img.shape[0])\n",
        "                x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
        "                #print(x_min, y_min, x_max, y_max)\n",
        "                cv2.putText(im_draw, class_label , (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "                cv2.rectangle(im_draw, (x_min,y_min), (x_max,y_max), (0,0,255),1)\n",
        "                filepath_image_save = f\"{folder_out_images_aug_check}/{i}_{basename}.png\"\n",
        "                tmp_aug_img_pil = Image.fromarray(im_draw)\n",
        "                tmp_aug_img_pil.save(filepath_image_save)\n",
        "\n",
        "\n",
        "            filepath_label_save = f\"{folder_labels_aug}/{i}_{basename}.txt\"\n",
        "            with open(filepath_label_save, 'w') as file:\n",
        "                # Save new images and labels\n",
        "                for box_yolo, class_label in zip(tr_bboxes_yolo, tr_class_labels):\n",
        "                    class_id = labels_name.index(class_label)\n",
        "                    x_center, y_center, width, height = box_yolo\n",
        "                    file.write(f\"{class_id} {x_center} {y_center} {width} {height} \\n\")\n",
        "\n",
        "\n",
        "            filepath_image_save = f\"{folder_images_aug}/{i}_{basename}.png\"\n",
        "            tr_img_pil = Image.fromarray(tr_img)\n",
        "            tr_img_pil.save(filepath_image_save)\n",
        "            #break\n",
        "\n",
        "def split_dataset(images_folder, labels_folder, output_folder, train_pct, val_pct, test_pct, random_seed=None):\n",
        "    \"\"\"\n",
        "    Split a dataset into training, validation, and testing sets based on specified percentages,\n",
        "    organizing images and labels into separate subfolders. Removes existing split folders if they exist.\n",
        "\n",
        "    Args:\n",
        "    - images_folder (str): Path to the folder containing images.\n",
        "    - labels_folder (str): Path to the folder containing corresponding labels.\n",
        "    - output_folder (str): Path to the folder where the split datasets will be saved.\n",
        "    - train_pct (float): Fraction of data to be used for training (e.g., 0.7 for 70%).\n",
        "    - val_pct (float): Fraction of data to be used for validation.\n",
        "    - test_pct (float): Fraction of data to be used for testing.\n",
        "    - random_seed (int, optional): Seed for the random number generator for reproducibility.\n",
        "    \"\"\"\n",
        "\n",
        "    assert train_pct + val_pct + test_pct == 1.0, \"Percentages must sum up to 1.0\"\n",
        "\n",
        "    if random_seed is not None:\n",
        "        random.seed(random_seed)\n",
        "\n",
        "    # Function to remove a directory if it exists\n",
        "    def remove_dir_if_exists(directory):\n",
        "        if os.path.exists(directory):\n",
        "            shutil.rmtree(directory)\n",
        "\n",
        "    # Remove existing directories if they exist\n",
        "    for subfolder in ['train', 'valid', 'test']:\n",
        "        remove_dir_if_exists(os.path.join(output_folder, subfolder))\n",
        "\n",
        "    # Create new output directories and subdirectories\n",
        "    for subfolder in ['train', 'valid', 'test']:\n",
        "        image_subfolder = os.path.join(output_folder, subfolder, 'images')\n",
        "        label_subfolder = os.path.join(output_folder, subfolder, 'labels')\n",
        "        os.makedirs(image_subfolder, exist_ok=True)\n",
        "        os.makedirs(label_subfolder, exist_ok=True)\n",
        "\n",
        "    # Get a list of filenames (without file extensions)\n",
        "    filenames = [os.path.splitext(file)[0] for file in os.listdir(images_folder) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    # Shuffle the filenames\n",
        "    random.shuffle(filenames)\n",
        "\n",
        "    # Calculate split indices\n",
        "    total_files = len(filenames)\n",
        "    split_train = int(train_pct * total_files)\n",
        "    split_val = split_train + int(val_pct * total_files)\n",
        "\n",
        "    # Split filenames\n",
        "    train_filenames = filenames[:split_train]\n",
        "    val_filenames = filenames[split_train:split_val]\n",
        "    test_filenames = filenames[split_val:]\n",
        "\n",
        "    # Function to copy files\n",
        "    def copy_files(filenames, src_img_folder, src_lbl_folder, dst_img_folder, dst_lbl_folder):\n",
        "        for filename in filenames:\n",
        "            shutil.copy2(os.path.join(src_img_folder, filename + '.png'), dst_img_folder)\n",
        "            shutil.copy2(os.path.join(src_lbl_folder, filename + '.txt'), dst_lbl_folder)\n",
        "\n",
        "    # Copy files to respective directories\n",
        "    copy_files(train_filenames, images_folder, labels_folder, os.path.join(output_folder, 'train', 'images'), os.path.join(output_folder, 'train', 'labels'))\n",
        "    copy_files(val_filenames, images_folder, labels_folder, os.path.join(output_folder, 'valid', 'images'), os.path.join(output_folder, 'valid', 'labels'))\n",
        "    copy_files(test_filenames, images_folder, labels_folder, os.path.join(output_folder, 'test', 'images'), os.path.join(output_folder, 'test', 'labels'))\n",
        "\n",
        "    print(\"Dataset split complete.\")\n",
        "\n",
        "def train(folder_export_labelstudio, model_name, pretrained_model=\"yolov8n.pt\", transform=None, segment=False):\n",
        "\n",
        "    folder_tmp_training = f\"{folder_export_labelstudio}/tmp_yolov8_training\"\n",
        "    folder_out_models = f\"{folder_export_labelstudio}/models\"\n",
        "    if not os.path.exists(folder_out_models):\n",
        "        os.makedirs(folder_out_models)\n",
        "\n",
        "    with open(f\"{folder_export_labelstudio}/data.yaml\", 'r') as file:\n",
        "        data = yaml.safe_load(file)\n",
        "        labels_name = data['names']\n",
        "\n",
        "    #f = open(f\"{folder_export_labelstudio}/notes.json\")\n",
        "    #info_data = json.load(f)\n",
        "    #labels_name = [info_data[\"categories\"][i][\"name\"] for i in range(0,len(info_data[\"categories\"]))]\n",
        "\n",
        "    if os.path.exists(folder_tmp_training):\n",
        "        shutil.rmtree(folder_tmp_training)\n",
        "    os.makedirs(folder_tmp_training)\n",
        "\n",
        "    folder_inp_images = f\"{folder_export_labelstudio}/images\"\n",
        "    folder_inp_labels = f\"{folder_export_labelstudio}/labels\"\n",
        "    folder_out_images_aug = f\"{folder_tmp_training}/images\"\n",
        "    folder_out_labels_aug = f\"{folder_tmp_training}/labels\"\n",
        "    folder_out_images_aug_check = f\"{folder_tmp_training}/aug\"\n",
        "\n",
        "    # DETECTION LIN\n",
        "    if segment:\n",
        "        # Augment data\n",
        "        augment_yolov8_seg(transform, folder_inp_images, folder_inp_labels, folder_out_images_aug, folder_out_labels_aug, labels_name, folder_out_images_aug_check)\n",
        "    else:\n",
        "        augment_yolov8_det(transform, folder_inp_images, folder_inp_labels, folder_out_images_aug, folder_out_labels_aug, labels_name, folder_out_images_aug_check)\n",
        "\n",
        "    # Split data into train test val\n",
        "    split_dataset(folder_out_images_aug, folder_out_labels_aug, folder_tmp_training, 0.7, 0.15, 0.15, random_seed=42)\n",
        "\n",
        "    # Define the data to be written to the YAML file\n",
        "    data = {\n",
        "        \"train\": f\"{folder_tmp_training}/train/images\",\n",
        "        \"val\":   f\"{folder_tmp_training}/valid/images\",\n",
        "        \"test\":  f\"{folder_tmp_training}/test/images\",\n",
        "        \"nc\": len(labels_name),\n",
        "        \"names\": labels_name,\n",
        "    }\n",
        "    # Create and write to the YAML file\n",
        "    yaml_file_path = f'{folder_tmp_training}/data.yaml'\n",
        "    with open(yaml_file_path, 'w') as file:\n",
        "        yaml.dump(data, file, sort_keys=False)\n",
        "\n",
        "    project=f\"{folder_tmp_training}/models\"\n",
        "    if segment:\n",
        "        # Traing yolov8\n",
        "        model = YOLO(pretrained_model, task=\"segment\")\n",
        "    else:\n",
        "        model = YOLO(pretrained_model)\n",
        "\n",
        "    results = model.train(data=yaml_file_path, epochs=100, imgsz=640, device=0, batch=4, project=project, name=model_name)\n",
        "\n",
        "    # Start tensorboard open a terminal and run\n",
        "    #tensorboard --logdir /home/manuel/builds/idea/idea_anomaly/app/data/datasets/models/runs/mat\n",
        "\n",
        "    # Copy best model to yolov8 folder\n",
        "    last_model_path = f\"{project}/{model_name}/weights/last.pt\"\n",
        "    best_model_path = f\"{project}/{model_name}/weights/best.pt\"\n",
        "    dst_last_model_path = f\"{folder_export_labelstudio}/models/{model_name}_last.pt\"\n",
        "    dst_best_model_path = f\"{folder_export_labelstudio}/models/{model_name}_best.pt\"\n",
        "    shutil.copy(best_model_path, dst_best_model_path)\n",
        "    shutil.copy(last_model_path, dst_last_model_path)\n",
        "    print(f\"Model path best: {dst_best_model_path}\")\n",
        "    print(f\"Model path last: {dst_last_model_path}\")\n"
      ],
      "metadata": {
        "id": "0RKKecC_lWOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downlaod Dataset"
      ],
      "metadata": {
        "id": "sszalgOxm7v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [Deep learning course datasets](https://drive.google.com/drive/folders/1tEypEI3lZjff0Z8GOyeANJ3qBg46Vhzi?usp=sharing)"
      ],
      "metadata": {
        "id": "TEXqZlAF319B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip halcon_mvtect_wood_segmentation_yolov8.zip  -d halcon_mvtect_wood_segmentation_yolov8\n",
        "!mv halcon_mvtect_wood_segmentation_yolov8/train/images halcon_mvtect_wood_segmentation_yolov8/images\n",
        "!mv halcon_mvtect_wood_segmentation_yolov8/train/labels halcon_mvtect_wood_segmentation_yolov8/labels\n",
        "!rm -rf  halcon_mvtect_wood_segmentation_yolov8/README.dataset.txt\n",
        "!rm -rf  halcon_mvtect_wood_segmentation_yolov8/README.roboflow.txt"
      ],
      "metadata": {
        "id": "xXLWpXqkwpR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Detection Model"
      ],
      "metadata": {
        "id": "Bh4lHHV7keiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_detection():\n",
        "    folder_dataset = f\"halcon_mvtect_wood_segmentation_yolov8_det\"\n",
        "    folder_dataset = os.path.join(os.getcwd(),folder_dataset)\n",
        "    model_name = \"yolov8n_det\"\n",
        "    pretrained_model = \"yolov8n.pt\"\n",
        "    transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        #A.ShiftScaleRotate( shift_limit=0.005, scale_limit=0, rotate_limit=90, p=0.8, border_mode=cv2.BORDER_CONSTANT),\n",
        "        A.ColorJitter(p=0.5,contrast=0.3, saturation=0.3, hue=0.5, brightness=0.2),\n",
        "        #A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), always_apply=False, p=0.3),\n",
        "        #A.GaussianBlur(p=0.5, blur_limit=(3, 9))\n",
        "    ], bbox_params=A.BboxParams(format='yolo', label_fields=[\"class_labels\"]))\n",
        "    train(folder_dataset, model_name, pretrained_model, transform, segment=False)"
      ],
      "metadata": {
        "id": "1QYtopHrvMp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_segmentation():\n",
        "    folder_dataset = \"halcon_mvtect_wood_segmentation_yolov8_seg\"\n",
        "    folder_dataset = os.path.join(os.getcwd(),folder_dataset)\n",
        "    model_name = \"yolov8n_seg\"\n",
        "    pretrained_model = \"yolov8n-seg.pt\"\n",
        "    transform = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Rotate(limit=(-90,90), p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
        "        A.ColorJitter(p=0.5,contrast=0.3, saturation=0.3, hue=0.5, brightness=(0.9,1.2)),\n",
        "    ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=True, label_fields=['class_labels']))\n",
        "    train(folder_dataset, model_name, pretrained_model, transform, segment=True)\n"
      ],
      "metadata": {
        "id": "oGck_f5an4zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_segmentation()"
      ],
      "metadata": {
        "id": "m_5LSJF0xrLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics and Results"
      ],
      "metadata": {
        "id": "n3A8bPYloKJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import imutils\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "vgEoprHv8HF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_rows(score_dict):\n",
        "    if isinstance(score_dict[\"label\"], list):\n",
        "        # If the label is a list, return its length\n",
        "        return len(score_dict[\"label\"])\n",
        "    else:\n",
        "        # If the label is a single element, count it as one row\n",
        "        return 1\n",
        "\n",
        "class Yolov8Inference:\n",
        "    def __init__(self, model_path, gpu=False):\n",
        "        self.model = YOLO(model_path)\n",
        "\n",
        "        self.device = torch.device(\"cpu\")\n",
        "        if gpu:\n",
        "            if torch.cuda.is_available():\n",
        "                self.device = torch.device(\"cuda\")\n",
        "                print(f\"Model will run on GPU: {torch.cuda.get_device_name(0)}\")\n",
        "            else:\n",
        "                print(\"Model will run on CPU, because GPU is not available\")\n",
        "        else:\n",
        "            print(\"Model will run on CPU\")\n",
        "\n",
        "        self.labels = self.model.names\n",
        "\n",
        "    def filter_score_dict(self, df, th_dict):\n",
        "        \"\"\"\n",
        "        Questa funzione prende come input\n",
        "        th_dict = {'bolla': 0.1, 'bordo_deformazione': 0.2,'deformazione': 0.5, 'solco': 0.1,'taglio': 0.1}\n",
        "        dove th_dict rappresenta i thresholds associati ad ogni classe\n",
        "        e\n",
        "        score_dict= {'bolla': 0, 'bordo_deformazione': 0, 'deformazione': 0, 'solco': 0, 'taglio': 0.8709222078323364}\n",
        "        dove score_dict rappresenta il massimo score trovato per ogni classe\n",
        "        \"\"\"\n",
        "\n",
        "        score_dict_filt = {key: [] for key in df.keys()}\n",
        "        for index, row in df.iterrows():\n",
        "            label = row[\"label\"]\n",
        "            score = row[\"score\"]\n",
        "            th = th_dict[label]\n",
        "            if (score > th):\n",
        "                for l in df.keys():\n",
        "                    score_dict_filt[l].append(row[l])\n",
        "\n",
        "        df_filt = pd.DataFrame(score_dict_filt)\n",
        "        return df_filt\n",
        "\n",
        "    def get_score_max_for_each_class(self, df):\n",
        "        # Find the entry with the max score for each label\n",
        "        max_df = df.loc[df.groupby('label')['score'].idxmax()]\n",
        "        return max_df\n",
        "\n",
        "    def predict(self, im, th_dict=None, is_seg=False, debug=False):\n",
        "\n",
        "        # im has to be numpy array\n",
        "        # start = time.time()\n",
        "        res = self.model.predict(im, imgsz=640, device=self.device, conf=0.01, iou=0.01, verbose=False)\n",
        "        # end = time.time()\n",
        "        # print(f\"Model inference: {end-start:2f}s\")\n",
        "\n",
        "        names = res[0].names\n",
        "        scores = res[0].boxes.conf.cpu().numpy()\n",
        "        class_ids = res[0].boxes.cls.cpu().numpy()\n",
        "        boxes = res[0].boxes.xyxy.cpu().numpy()\n",
        "        if is_seg and len(scores) > 0:\n",
        "            # Segmetnation model\n",
        "            masks = res[0].masks.data.cpu().numpy()\n",
        "\n",
        "        # Create score dict\n",
        "        if is_seg:\n",
        "            score_dict = {\n",
        "                \"label\": [],\n",
        "                \"score\": [],\n",
        "                \"xyxy\": [],\n",
        "                \"cnt\": []\n",
        "            }\n",
        "        else:\n",
        "            score_dict = {\n",
        "                \"label\": [],\n",
        "                \"score\": [],\n",
        "                \"xyxy\": [],\n",
        "            }\n",
        "        for box, score, class_id in zip(boxes, scores, class_ids):\n",
        "            x1, y1, x2, y2 = box.astype(int)\n",
        "            score_dict[\"label\"].append(names[class_id])\n",
        "            score_dict[\"score\"].append(score)\n",
        "            score_dict[\"xyxy\"].append([x1, y1, x2, y2])\n",
        "\n",
        "        if is_seg and len(scores) > 0:\n",
        "            for mask, class_id, score in zip(masks, class_ids, scores):\n",
        "                label = names[class_id]\n",
        "                mask = (mask * 255).astype(np.uint8)\n",
        "                h = im.shape[0]\n",
        "                w = im.shape[1]\n",
        "                mask = cv2.resize(mask, (w, h))\n",
        "                _, binary_mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
        "                contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                if len(contours) > 0:\n",
        "                    c_max = max(contours, key=cv2.contourArea)\n",
        "                    score_dict[\"cnt\"].append(c_max)\n",
        "                else:\n",
        "                    score_dict[\"cnt\"].append([])\n",
        "        df = pd.DataFrame(score_dict)\n",
        "\n",
        "        # Get score_max for each class (THIS is NOT USEFUL)\n",
        "        # df = self.get_score_max_for_each_class(df)\n",
        "\n",
        "        # Filter results according to the thresholds\n",
        "        if th_dict is not None:\n",
        "            df = self.filter_score_dict(df, th_dict)\n",
        "\n",
        "        score_max = 0\n",
        "        label_max = \"\"\n",
        "        if len(df) > 0:\n",
        "            # print(f\"{filename}: {score_max}\")\n",
        "            score_vec = df[\"score\"].values\n",
        "            score_max_idx = np.argmax(score_vec)\n",
        "            score_max = score_vec[score_max_idx]\n",
        "            label_max = df[\"label\"][score_max_idx]\n",
        "\n",
        "        score_dict = df.to_dict(orient='list')\n",
        "        return score_dict, score_max, label_max"
      ],
      "metadata": {
        "id": "5aE3Ylfl7-HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inf = Yolov8Inference(\"/content/halcon_mvtect_wood_segmentation_yolov8/models/yolov8n_seg_mat_v13_best.pt\", True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsau-8H_7HQk",
        "outputId": "a50cca86-9c1c-476a-f26e-628b46cb55a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model will run on GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th_dict = {\n",
        "    \"liquid\": 0.1,\n",
        "    \"scratch\": 0.1,\n",
        "    \"hole\": 0.1\n",
        "}\n",
        "is_seg = True"
      ],
      "metadata": {
        "id": "vxZhTBl99E9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_seg = True\n",
        "folder_path = \"halcon_mvtect_wood_segmentation_yolov8/images\"\n",
        "images_list = []\n",
        "filename_list = []\n",
        "for name in sorted(os.listdir(folder_path)):\n",
        "    filename = os.path.join(folder_path, name)\n",
        "    im = Image.open(filename)\n",
        "    im = np.array(im)\n",
        "\n",
        "    score_dict, score_max, label_max = inf.predict(im, th_dict, is_seg)\n",
        "\n",
        "    im_draw = im.copy()\n",
        "\n",
        "    num_rows_dict = count_rows(score_dict)\n",
        "    for i in range(0, num_rows_dict):\n",
        "        label = score_dict[\"label\"][i]\n",
        "        score = score_dict[\"score\"][i]\n",
        "\n",
        "        if not is_seg:\n",
        "            x1, y1, x2, y2 = score_dict[\"xyxy\"][i]\n",
        "            cv2.rectangle(im_draw, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
        "            cv2.putText(im_draw, f\"{label}: {score:.2f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        (255, 255, 255), 1)\n",
        "        else:\n",
        "            cnt = score_dict[\"cnt\"][i]\n",
        "            cv2.drawContours(im_draw, [cnt], -1, (0, 0, 255), 1)  # Adjust thickness and color as needed\n",
        "            rect = cv2.minAreaRect(cnt)\n",
        "            box = cv2.boxPoints(rect)\n",
        "            box = np.intp(box)  # convert to integer\n",
        "            M = cv2.moments(cnt)\n",
        "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "            cv2.drawContours(im_draw, [box], -1, (0, 255, 0), 1)  # Adjust thickness and color as needed\n",
        "            cv2.putText(im_draw, f\"{label}: {score:.2f}\", (cx, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        (255, 255, 255), 1)\n",
        "\n",
        "    #cv2.putText(im_draw, f\"{res_string}\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
        "    #print(filename)\n",
        "    #display(Image.fromarray(im_draw).resize((256,256)))\n",
        "    images_list.append(im_draw)\n",
        "    filename_list.append(filename)\n",
        "    #break"
      ],
      "metadata": {
        "id": "IYN3h5rr7I70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save on colab"
      ],
      "metadata": {
        "id": "batkc1Zi7ZEd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}