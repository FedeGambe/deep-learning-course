{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"60.2_Stemming.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"CQe30UhIyTkh"},"source":["# Stemming\n","Often when searching text for a certain keyword, it helps if the search returns variations of the word. For instance, searching for \"boat\" might also return \"boats\" and \"boating\". Here, \"boat\" would be the **stem** for [boat, boater, boating, boats].\n","\n","Stemming is a somewhat crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached.\n","\n","Instead, we'll use another popular NLP tool called **nltk**, which stands for *Natural Language Toolkit*. For more information on nltk visit https://www.nltk.org/"]},{"cell_type":"markdown","metadata":{"id":"zWgvjChVyTki"},"source":["## Porter Stemmer\n","\n","One of the most common - and effective - stemming tools is [*Porter's Algorithm*](https://tartarus.org/martin/PorterStemmer/) developed by Martin Porter in [1980](https://tartarus.org/martin/PorterStemmer/def.txt). The algorithm employs five phases of word reduction, each with its own set of mapping rules. In the first phase, simple suffix mapping rules are defined, such as:"]},{"cell_type":"markdown","metadata":{"id":"wHaKYCWpyTki"},"source":["![stemming1.png](https://frenzy86.s3.eu-west-2.amazonaws.com/IFAO/nlp/stemming1.png)"]},{"cell_type":"markdown","metadata":{"id":"byJCEzOpyTki"},"source":["From a given set of stemming rules only one rule is applied, based on the longest suffix S1. Thus, `caresses` reduces to `caress` but not `cares`.\n","\n","More sophisticated phases consider the length/complexity of the word before applying a rule. For example:"]},{"cell_type":"markdown","metadata":{"id":"I6XdJ3jVyTki"},"source":["![stemming1.png](https://frenzy86.s3.eu-west-2.amazonaws.com/IFAO/nlp/stemming2.png)"]},{"cell_type":"markdown","metadata":{"id":"yAmft9shyTkj"},"source":["Here `m>0` describes the \"measure\" of the stem, such that the rule is applied to all but the most basic stems."]},{"cell_type":"code","metadata":{"id":"pFpijKCuyTkj"},"source":["# Import the toolkit and the full Porter Stemmer library\n","import nltk\n","\n","from nltk.stem.porter import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTq4EsIAyTkj"},"source":["p_stemmer = PorterStemmer()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xNqJfgyfyTkj"},"source":["words = ['run','runner','running','ran','runs','easily','fairly']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rwYRQaLyTkk","executionInfo":{"status":"ok","timestamp":1617018166420,"user_tz":-120,"elapsed":325,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"a084431b-a584-4bcf-c595-23e54d6e985f"},"source":["for word in words:\n","    print(word+' --> '+p_stemmer.stem(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["run --> run\n","runner --> runner\n","running --> run\n","ran --> ran\n","runs --> run\n","easily --> easili\n","fairly --> fairli\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h0justuAyTkk"},"source":["<font color=green>Note how the stemmer recognizes \"runner\" as a noun, not a verb form or participle. Also, the adverbs \"easily\" and \"fairly\" are stemmed to the unusual root \"easili\" and \"fairli\"</font>\n","___"]},{"cell_type":"markdown","metadata":{"id":"BWYujIQHyTkk"},"source":["## Snowball Stemmer - Italian\n","This is somewhat of a misnomer, as Snowball is the name of a stemming language developed by Martin Porter. The algorithm used here is more acurately called the \"English Stemmer\" or \"Porter2 Stemmer\". It offers a slight improvement over the original Porter stemmer, both in logic and speed. Since **nltk** uses the name SnowballStemmer, we'll use it here."]},{"cell_type":"code","metadata":{"id":"B-cjDk3eyTkk"},"source":["from nltk.stem.snowball import SnowballStemmer\n","\n","# The Snowball Stemmer requires that you pass a language parameter\n","s_stemmer = SnowballStemmer(language='italian')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7dTYNyPyTkl"},"source":["words = ['divertente','diverte','divertito','divertire','mio','miei']\n","# words = ['generous','generation','generously','generate']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1Vy_AwcyTkl","executionInfo":{"status":"ok","timestamp":1617018745486,"user_tz":-120,"elapsed":374,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"61d1f087-ffe6-4f85-8656-4e0c944d04a7"},"source":["for word in words:\n","    print(word+' --> '+s_stemmer.stem(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["divertente --> divertent\n","diverte --> divert\n","divertito --> divert\n","divertire --> divert\n","mio --> mio\n","miei --> mie\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"NUFot7knyTkl"},"source":["<font color=green>In this case the stemmer performed the same as the Porter Stemmer, with the exception that it handled the stem of \"fairly\" more appropriately with \"fair\"</font>\n","___"]},{"cell_type":"markdown","metadata":{"id":"mt0X91PVyTkl"},"source":["## Esercizi"]},{"cell_type":"code","metadata":{"id":"ls-lnacdyTkl"},"source":["words = ['consigliammo']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXWcPEiYyTkm","executionInfo":{"status":"ok","timestamp":1617018775821,"user_tz":-120,"elapsed":437,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"11e05324-6e42-4cc2-f45b-b145847abf8a"},"source":["print('Porter Stemmer:')\n","for word in words:\n","    print(word+' --> '+p_stemmer.stem(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Porter Stemmer:\n","consigliammo --> consigliammo\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aU9q0oAJyTkm","executionInfo":{"status":"ok","timestamp":1617018781642,"user_tz":-120,"elapsed":433,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"9f076d92-aa42-4231-c23b-d9e10a9f373f"},"source":["print('Porter2 Stemmer:')\n","for word in words:\n","    print(word+' --> '+s_stemmer.stem(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Porter2 Stemmer:\n","consigliammo --> consigl\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qI9kG9WRyTkm"},"source":["___\n","Stemming has its drawbacks. If given the token `saw`, stemming might always return `saw`, whereas lemmatization would likely return either `see` or `saw` depending on whether the use of the token was as a verb or a noun. As an example, consider the following:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gSJYaMK-yTkm","executionInfo":{"status":"ok","timestamp":1617018828953,"user_tz":-120,"elapsed":502,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"50cf9f4e-a886-43b2-fce4-31fbc74babcf"},"source":["phrase = 'Giocare a bowling con i miei amici mi diverte molto'\n","for word in phrase.split():\n","    print(word+' --> '+p_stemmer.stem(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Giocare --> giocar\n","a --> a\n","bowling --> bowl\n","con --> con\n","i --> i\n","miei --> miei\n","amici --> amici\n","mi --> mi\n","diverte --> divert\n","molto --> molto\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kQDWb4M_zqXQ"},"source":["### Stemming and Lemmatization"]},{"cell_type":"markdown","metadata":{"id":"vJXdUmdjzTvu"},"source":["üí° ‚ÄúStemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes‚Ä¶.Stemmers use language-specific rules, but they require less knowledge than a lemmatizer‚Ä¶‚Äù\n","\n","üí° ‚ÄúLemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma‚Ä¶.a lemmatizer, which needs a complete vocabulary and morphological analysis to correctly lemmatize words‚Ä¶‚Äù"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcx6K2RwzcYM","executionInfo":{"status":"ok","timestamp":1617018343876,"user_tz":-120,"elapsed":1472,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"72a88f98-33a2-4e02-e66f-d41e7f281ead"},"source":["## import nltk\n","nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"NJtaTcQFzSUf"},"source":["# Import packages\n","import pandas as pd\n","from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n","# Instantiate stemmers and lemmatiser\n","porter = PorterStemmer()\n","lancaster = LancasterStemmer()\n","lemmatiser = WordNetLemmatizer()\n","# Create function that normalises text using all three techniques\n","def normalise_text(words, pos='v'):\n","    \"\"\"Stem and lemmatise each word in a list. Return output in a dataframe.\"\"\"\n","    normalised_text = pd.DataFrame(index=words, columns=['Porter', 'Lancaster', 'Lemmatiser'])\n","    for word in words:\n","        normalised_text.loc[word,'Porter'] = porter.stem(word)\n","        normalised_text.loc[word,'Lancaster'] = lancaster.stem(word)\n","        normalised_text.loc[word,'Lemmatiser'] = lemmatiser.lemmatize(word, pos=pos)\n","    return normalised_text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NdiawQZiz6QV"},"source":["üí° PorterStemmer: One of the most commonly used stemmers. It is based on Porter Stemming Algorithm. For more information, check out the official web page: https://tartarus.org/martin/PorterStemmer/\n","\n","üí° LancasterStemmer: It is based on Lancaster Stemming Algorithm and can sometimes result in more aggressive stemming than PorterStemmer."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"1HRPstK-zSvR","executionInfo":{"status":"ok","timestamp":1617018428761,"user_tz":-120,"elapsed":511,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"5bc701e7-ab65-4633-d26b-013f0add90d4"},"source":["normalise_text(['apples', 'pears', 'tasks', 'children', 'earrings', \n","                'dictionary', 'marriage', 'connections', 'universe', 'university'], pos='n')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Porter</th>\n","      <th>Lancaster</th>\n","      <th>Lemmatiser</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>apples</th>\n","      <td>appl</td>\n","      <td>appl</td>\n","      <td>apple</td>\n","    </tr>\n","    <tr>\n","      <th>pears</th>\n","      <td>pear</td>\n","      <td>pear</td>\n","      <td>pear</td>\n","    </tr>\n","    <tr>\n","      <th>tasks</th>\n","      <td>task</td>\n","      <td>task</td>\n","      <td>task</td>\n","    </tr>\n","    <tr>\n","      <th>children</th>\n","      <td>children</td>\n","      <td>childr</td>\n","      <td>child</td>\n","    </tr>\n","    <tr>\n","      <th>earrings</th>\n","      <td>ear</td>\n","      <td>ear</td>\n","      <td>earring</td>\n","    </tr>\n","    <tr>\n","      <th>dictionary</th>\n","      <td>dictionari</td>\n","      <td>dict</td>\n","      <td>dictionary</td>\n","    </tr>\n","    <tr>\n","      <th>marriage</th>\n","      <td>marriag</td>\n","      <td>marry</td>\n","      <td>marriage</td>\n","    </tr>\n","    <tr>\n","      <th>connections</th>\n","      <td>connect</td>\n","      <td>connect</td>\n","      <td>connection</td>\n","    </tr>\n","    <tr>\n","      <th>universe</th>\n","      <td>univers</td>\n","      <td>univers</td>\n","      <td>universe</td>\n","    </tr>\n","    <tr>\n","      <th>university</th>\n","      <td>univers</td>\n","      <td>univers</td>\n","      <td>university</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Porter Lancaster  Lemmatiser\n","apples             appl      appl       apple\n","pears              pear      pear        pear\n","tasks              task      task        task\n","children       children    childr       child\n","earrings            ear       ear     earring\n","dictionary   dictionari      dict  dictionary\n","marriage        marriag     marry    marriage\n","connections     connect   connect  connection\n","universe        univers   univers    universe\n","university      univers   univers  university"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"eePxzQMJzuya","executionInfo":{"status":"ok","timestamp":1617018547445,"user_tz":-120,"elapsed":564,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"5256eb5d-3c77-416f-a02e-f7a62ee6b8c1"},"source":["normalise_text(['wrote', 'thinking', 'remembered', 'relies', 'ate', 'gone', 'won',\n","                'ran', 'swimming', 'mistreated'], pos='v')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Porter</th>\n","      <th>Lancaster</th>\n","      <th>Lemmatiser</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>wrote</th>\n","      <td>wrote</td>\n","      <td>wrot</td>\n","      <td>write</td>\n","    </tr>\n","    <tr>\n","      <th>thinking</th>\n","      <td>think</td>\n","      <td>think</td>\n","      <td>think</td>\n","    </tr>\n","    <tr>\n","      <th>remembered</th>\n","      <td>rememb</td>\n","      <td>rememb</td>\n","      <td>remember</td>\n","    </tr>\n","    <tr>\n","      <th>relies</th>\n","      <td>reli</td>\n","      <td>rely</td>\n","      <td>rely</td>\n","    </tr>\n","    <tr>\n","      <th>ate</th>\n","      <td>ate</td>\n","      <td>at</td>\n","      <td>eat</td>\n","    </tr>\n","    <tr>\n","      <th>gone</th>\n","      <td>gone</td>\n","      <td>gon</td>\n","      <td>go</td>\n","    </tr>\n","    <tr>\n","      <th>won</th>\n","      <td>won</td>\n","      <td>won</td>\n","      <td>win</td>\n","    </tr>\n","    <tr>\n","      <th>ran</th>\n","      <td>ran</td>\n","      <td>ran</td>\n","      <td>run</td>\n","    </tr>\n","    <tr>\n","      <th>swimming</th>\n","      <td>swim</td>\n","      <td>swim</td>\n","      <td>swim</td>\n","    </tr>\n","    <tr>\n","      <th>mistreated</th>\n","      <td>mistreat</td>\n","      <td>mist</td>\n","      <td>mistreat</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Porter Lancaster Lemmatiser\n","wrote          wrote      wrot      write\n","thinking       think     think      think\n","remembered    rememb    rememb   remember\n","relies          reli      rely       rely\n","ate              ate        at        eat\n","gone            gone       gon         go\n","won              won       won        win\n","ran              ran       ran        run\n","swimming        swim      swim       swim\n","mistreated  mistreat      mist   mistreat"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"JboLwA-W0Nuq"},"source":[""],"execution_count":null,"outputs":[]}]}