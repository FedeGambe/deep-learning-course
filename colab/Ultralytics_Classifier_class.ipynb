{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ultralytics Classifier"
      ],
      "metadata": {
        "id": "6NwwliogBETy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up runtime to use GPU"
      ],
      "metadata": {
        "id": "xK_eUvfjBI8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create or get the dataset"
      ],
      "metadata": {
        "id": "MjQ_B2F_tUfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.mvtec.com/company/research/datasets/mvtec-ad/downloads\n",
        "# Get bottle dataset\n",
        "!wget https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420937370-1629951468/bottle.tar.xz"
      ],
      "metadata": {
        "id": "gL-a_7mktWqm",
        "outputId": "f1fe98ba-79f7-4c60-f26d-40d7895f5f48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-16 16:31:54--  https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420937370-1629951468/bottle.tar.xz\n",
            "Resolving www.mydrive.ch (www.mydrive.ch)... 91.214.169.64\n",
            "Connecting to www.mydrive.ch (www.mydrive.ch)|91.214.169.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 155880244 (149M) [application/x-xz]\n",
            "Saving to: ‘bottle.tar.xz’\n",
            "\n",
            "bottle.tar.xz       100%[===================>] 148.66M  19.3MB/s    in 9.0s    \n",
            "\n",
            "2024-10-16 16:32:04 (16.4 MB/s) - ‘bottle.tar.xz’ saved [155880244/155880244]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf bottle.tar.xz"
      ],
      "metadata": {
        "id": "70RFkr4out0A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "l4juVgceaz05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import yaml\n",
        "# pathlib\n",
        "\n",
        "def get_filenames(folder):\n",
        "    filenames = []\n",
        "    for f in folder:\n",
        "        for file in os.listdir(f):\n",
        "            filename = os.path.join(f, file)\n",
        "            filenames.append(filename)\n",
        "    return filenames\n",
        "\n",
        "def split_train_test_val(filenames, train_pct, test_pct, val_pct):\n",
        "    random.shuffle(filenames)\n",
        "\n",
        "    # Calculate split indices\n",
        "    total_files = len(filenames)\n",
        "    split_train = int(train_pct * total_files)\n",
        "    split_val = split_train + int(val_pct * total_files)\n",
        "\n",
        "    # Split filenames\n",
        "    train_filenames = filenames[:split_train]\n",
        "    val_filenames = filenames[split_train:split_val]\n",
        "    test_filenames = filenames[split_val:]\n",
        "    return train_filenames, val_filenames, test_filenames\n",
        "\n",
        "shutil.rmtree(\"dataset\")\n",
        "\n",
        "folder_ok = [\"bottle/train/good\"]\n",
        "#folder_nok = [\"bottle/test/broken_large\",\"bottle/test/broken_small\",\"bottle/test/contamination\"]\n",
        "folder_broken_large = [\"bottle/test/broken_large\"]\n",
        "folder_broken_small = [\"bottle/test/broken_small\"]\n",
        "folder_contamination = [\"bottle/test/contamination\"]\n",
        "\n",
        "filenames_nok = get_filenames(folder_nok)\n",
        "filenames_ok = get_filenames(folder_ok)\n",
        "filenames_broken_large = get_filenames(folder_broken_large)\n",
        "filenames_broken_small = get_filenames(folder_broken_small)\n",
        "filenames_contamination = get_filenames(folder_contamination)\n",
        "\n",
        "d = {\n",
        "    \"ok\": filenames_ok,\n",
        "    \"broken_large\": filenames_broken_large,\n",
        "    \"broken_small\": filenames_broken_small,\n",
        "    \"contamination\": filenames_contamination\n",
        "}\n",
        "classes = list(d.keys())\n",
        "for clas in classes:\n",
        "    train_filenames, val_filenames, test_filenames = split_train_test_val(d[clas], 0.7,0.2,0.1)\n",
        "    tasks = [\"train\", \"test\",\"val\"]\n",
        "    for task in tasks:\n",
        "        folder_dst= f\"dataset/{task}/{clas}\"\n",
        "        os.makedirs(folder_dst, exist_ok=True)\n",
        "        if task == \"train\":\n",
        "            for f in train_filenames:\n",
        "                shutil.copy(f, folder_dst)\n",
        "        if task == \"test\":\n",
        "            for f in test_filenames:\n",
        "                shutil.copy(f, folder_dst)\n",
        "        if task == \"val\":\n",
        "            for f in val_filenames:\n",
        "                shutil.copy(f, folder_dst)\n",
        "\n",
        "dataset = \"/content/dataset\"\n",
        "data = {\n",
        "    \"train\": f\"{dataset}/train\",\n",
        "    \"val\":   f\"{dataset}/val\",\n",
        "    \"test\":  f\"{dataset}/test\",\n",
        "    \"nc\": len(classes),\n",
        "    \"names\": classes,\n",
        "}\n",
        "# Create and write to the YAML file\n",
        "yaml_file_path = f\"{dataset}/data.yaml\"\n",
        "with open(yaml_file_path, 'w') as file:\n",
        "    yaml.dump(data, file, sort_keys=False)\n"
      ],
      "metadata": {
        "id": "4UywekUbSDDK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8m-cls.pt\")\n",
        "results = model.train(data=\"/content/dataset\", epochs=30, imgsz=224,batch=4)"
      ],
      "metadata": {
        "id": "Gg1VLswaZW5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n"
      ],
      "metadata": {
        "id": "Nn8H8dP2bIlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Yolov8Inference:\n",
        "    def __init__(self, model_path, gpu=False):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.device = torch.device(\"cpu\")\n",
        "        if gpu:\n",
        "            if torch.cuda.is_available():\n",
        "                self.device = torch.device(\"cuda\")\n",
        "                print(f\"Model will run on GPU: {torch.cuda.get_device_name(0)}\")\n",
        "            else:\n",
        "                print(\"Model will run on CPU, because GPU is not available\")\n",
        "        else:\n",
        "            print(\"Model will run on CPU\")\n",
        "        self.labels = self.model.names\n",
        "\n",
        "    def predict(self, im):\n",
        "\n",
        "        # im has to be numpy array\n",
        "        # start = time.time()\n",
        "        res = self.model.predict(im, imgsz=640, device=self.device, conf=0.01, iou=0.01, verbose=False)\n",
        "        # end = time.time()\n",
        "        # print(f\"Model inference: {end-start:2f}s\")\n",
        "\n",
        "        #print(res[0].probs)\n",
        "        names = res[0].names\n",
        "        scores = res[0].probs.data.cpu().numpy()\n",
        "\n",
        "        im_draw = im.copy()\n",
        "        idx = np.argmax(scores)\n",
        "        score = scores[idx]\n",
        "        cv2.putText(im_draw, f\"{names[idx]}: {score:.2f}\", (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.5,(0, 0, 255), 1)\n",
        "\n",
        "        return im_draw\n",
        "\n"
      ],
      "metadata": {
        "id": "TkLwWJc1_G7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Yolov8Inference(\"/content/tmp_training/train/weights/best.pt\")\n",
        "for f in filename_ok:\n",
        "    im = cv2.imread(f, cv2.IMREAD_COLOR)\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    im_draw = model.predict(im)\n",
        "    display(Image.fromarray(im_draw).resize((512,512)))\n",
        "    break"
      ],
      "metadata": {
        "id": "qGP4gnGTbObd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}