{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"02_Breast_Cancer.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"2m4wdmw4fK0M"},"source":["# Reti neurali\n","**Winsconsis Breast Cancer Dataset**.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sKMGS-KkIhj","executionInfo":{"status":"ok","timestamp":1614700416293,"user_tz":-60,"elapsed":2144,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"2b95d8e6-17df-43ec-f78e-d01f794e1478"},"source":["import tensorflow\r\n","print(tensorflow.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lJxYV6OykSa7","executionInfo":{"status":"ok","timestamp":1614682368794,"user_tz":-60,"elapsed":401,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"40d22c8b-1497-4bf8-a4a6-9afc2bd0c13a"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwFahDDTkZDS","executionInfo":{"status":"ok","timestamp":1615290185379,"user_tz":-60,"elapsed":2975,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"579dc2c6-a95b-4f18-f99e-81eb7e2ff25d"},"source":["import tensorflow\r\n","print(tensorflow.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7dReRAZvfK0Q","executionInfo":{"status":"ok","timestamp":1615296482404,"user_tz":-60,"elapsed":1162,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import LabelEncoder\n","\n","# import the necessary packages\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense"],"execution_count":88,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6VVmaRU8fK0S"},"source":["Carichiamo il Winsconsis breast cancer dataset all'interno di un DataFrame."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453},"id":"SYPSpQqnfK0S","executionInfo":{"status":"ok","timestamp":1615296482716,"user_tz":-60,"elapsed":1160,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"4341042c-7df6-4cc9-d4cc-50eb1027a545"},"source":["df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\",\n","                        names=[\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\n","                               \"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\n","                               \"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\n","                               \"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\n","                               \"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\n","                               \"fractal_dimension_worst\"])\n","\n","df"],"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>diagnosis</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>symmetry_mean</th>\n","      <th>fractal_dimension_mean</th>\n","      <th>radius_se</th>\n","      <th>texture_se</th>\n","      <th>perimeter_se</th>\n","      <th>area_se</th>\n","      <th>smoothness_se</th>\n","      <th>compactness_se</th>\n","      <th>concavity_se</th>\n","      <th>concave points_se</th>\n","      <th>symmetry_se</th>\n","      <th>fractal_dimension_se</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842302</td>\n","      <td>M</td>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.30010</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>1.0950</td>\n","      <td>0.9053</td>\n","      <td>8.589</td>\n","      <td>153.40</td>\n","      <td>0.006399</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.006193</td>\n","      <td>25.380</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.16220</td>\n","      <td>0.66560</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>842517</td>\n","      <td>M</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.08690</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.990</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.12380</td>\n","      <td>0.18660</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84300903</td>\n","      <td>M</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.19740</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.570</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.14440</td>\n","      <td>0.42450</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84348301</td>\n","      <td>M</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.24140</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.910</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.20980</td>\n","      <td>0.86630</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>84358402</td>\n","      <td>M</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.19800</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.540</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.13740</td>\n","      <td>0.20500</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>564</th>\n","      <td>926424</td>\n","      <td>M</td>\n","      <td>21.56</td>\n","      <td>22.39</td>\n","      <td>142.00</td>\n","      <td>1479.0</td>\n","      <td>0.11100</td>\n","      <td>0.11590</td>\n","      <td>0.24390</td>\n","      <td>0.13890</td>\n","      <td>0.1726</td>\n","      <td>0.05623</td>\n","      <td>1.1760</td>\n","      <td>1.2560</td>\n","      <td>7.673</td>\n","      <td>158.70</td>\n","      <td>0.010300</td>\n","      <td>0.02891</td>\n","      <td>0.05198</td>\n","      <td>0.02454</td>\n","      <td>0.01114</td>\n","      <td>0.004239</td>\n","      <td>25.450</td>\n","      <td>26.40</td>\n","      <td>166.10</td>\n","      <td>2027.0</td>\n","      <td>0.14100</td>\n","      <td>0.21130</td>\n","      <td>0.4107</td>\n","      <td>0.2216</td>\n","      <td>0.2060</td>\n","      <td>0.07115</td>\n","    </tr>\n","    <tr>\n","      <th>565</th>\n","      <td>926682</td>\n","      <td>M</td>\n","      <td>20.13</td>\n","      <td>28.25</td>\n","      <td>131.20</td>\n","      <td>1261.0</td>\n","      <td>0.09780</td>\n","      <td>0.10340</td>\n","      <td>0.14400</td>\n","      <td>0.09791</td>\n","      <td>0.1752</td>\n","      <td>0.05533</td>\n","      <td>0.7655</td>\n","      <td>2.4630</td>\n","      <td>5.203</td>\n","      <td>99.04</td>\n","      <td>0.005769</td>\n","      <td>0.02423</td>\n","      <td>0.03950</td>\n","      <td>0.01678</td>\n","      <td>0.01898</td>\n","      <td>0.002498</td>\n","      <td>23.690</td>\n","      <td>38.25</td>\n","      <td>155.00</td>\n","      <td>1731.0</td>\n","      <td>0.11660</td>\n","      <td>0.19220</td>\n","      <td>0.3215</td>\n","      <td>0.1628</td>\n","      <td>0.2572</td>\n","      <td>0.06637</td>\n","    </tr>\n","    <tr>\n","      <th>566</th>\n","      <td>926954</td>\n","      <td>M</td>\n","      <td>16.60</td>\n","      <td>28.08</td>\n","      <td>108.30</td>\n","      <td>858.1</td>\n","      <td>0.08455</td>\n","      <td>0.10230</td>\n","      <td>0.09251</td>\n","      <td>0.05302</td>\n","      <td>0.1590</td>\n","      <td>0.05648</td>\n","      <td>0.4564</td>\n","      <td>1.0750</td>\n","      <td>3.425</td>\n","      <td>48.55</td>\n","      <td>0.005903</td>\n","      <td>0.03731</td>\n","      <td>0.04730</td>\n","      <td>0.01557</td>\n","      <td>0.01318</td>\n","      <td>0.003892</td>\n","      <td>18.980</td>\n","      <td>34.12</td>\n","      <td>126.70</td>\n","      <td>1124.0</td>\n","      <td>0.11390</td>\n","      <td>0.30940</td>\n","      <td>0.3403</td>\n","      <td>0.1418</td>\n","      <td>0.2218</td>\n","      <td>0.07820</td>\n","    </tr>\n","    <tr>\n","      <th>567</th>\n","      <td>927241</td>\n","      <td>M</td>\n","      <td>20.60</td>\n","      <td>29.33</td>\n","      <td>140.10</td>\n","      <td>1265.0</td>\n","      <td>0.11780</td>\n","      <td>0.27700</td>\n","      <td>0.35140</td>\n","      <td>0.15200</td>\n","      <td>0.2397</td>\n","      <td>0.07016</td>\n","      <td>0.7260</td>\n","      <td>1.5950</td>\n","      <td>5.772</td>\n","      <td>86.22</td>\n","      <td>0.006522</td>\n","      <td>0.06158</td>\n","      <td>0.07117</td>\n","      <td>0.01664</td>\n","      <td>0.02324</td>\n","      <td>0.006185</td>\n","      <td>25.740</td>\n","      <td>39.42</td>\n","      <td>184.60</td>\n","      <td>1821.0</td>\n","      <td>0.16500</td>\n","      <td>0.86810</td>\n","      <td>0.9387</td>\n","      <td>0.2650</td>\n","      <td>0.4087</td>\n","      <td>0.12400</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>92751</td>\n","      <td>B</td>\n","      <td>7.76</td>\n","      <td>24.54</td>\n","      <td>47.92</td>\n","      <td>181.0</td>\n","      <td>0.05263</td>\n","      <td>0.04362</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.1587</td>\n","      <td>0.05884</td>\n","      <td>0.3857</td>\n","      <td>1.4280</td>\n","      <td>2.548</td>\n","      <td>19.15</td>\n","      <td>0.007189</td>\n","      <td>0.00466</td>\n","      <td>0.00000</td>\n","      <td>0.00000</td>\n","      <td>0.02676</td>\n","      <td>0.002783</td>\n","      <td>9.456</td>\n","      <td>30.37</td>\n","      <td>59.16</td>\n","      <td>268.6</td>\n","      <td>0.08996</td>\n","      <td>0.06444</td>\n","      <td>0.0000</td>\n","      <td>0.0000</td>\n","      <td>0.2871</td>\n","      <td>0.07039</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>569 rows × 32 columns</p>\n","</div>"],"text/plain":["           id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n","0      842302         M  ...          0.4601                  0.11890\n","1      842517         M  ...          0.2750                  0.08902\n","2    84300903         M  ...          0.3613                  0.08758\n","3    84348301         M  ...          0.6638                  0.17300\n","4    84358402         M  ...          0.2364                  0.07678\n","..        ...       ...  ...             ...                      ...\n","564    926424         M  ...          0.2060                  0.07115\n","565    926682         M  ...          0.2572                  0.06637\n","566    926954         M  ...          0.2218                  0.07820\n","567    927241         M  ...          0.4087                  0.12400\n","568     92751         B  ...          0.2871                  0.07039\n","\n","[569 rows x 32 columns]"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npivgy4HjS6w","executionInfo":{"status":"ok","timestamp":1615296482717,"user_tz":-60,"elapsed":1120,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"d4a36e52-48c1-4cbd-d2e4-78321b8c34af"},"source":["df.info()"],"execution_count":90,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 569 entries, 0 to 568\n","Data columns (total 32 columns):\n"," #   Column                   Non-Null Count  Dtype  \n","---  ------                   --------------  -----  \n"," 0   id                       569 non-null    int64  \n"," 1   diagnosis                569 non-null    object \n"," 2   radius_mean              569 non-null    float64\n"," 3   texture_mean             569 non-null    float64\n"," 4   perimeter_mean           569 non-null    float64\n"," 5   area_mean                569 non-null    float64\n"," 6   smoothness_mean          569 non-null    float64\n"," 7   compactness_mean         569 non-null    float64\n"," 8   concavity_mean           569 non-null    float64\n"," 9   concave points_mean      569 non-null    float64\n"," 10  symmetry_mean            569 non-null    float64\n"," 11  fractal_dimension_mean   569 non-null    float64\n"," 12  radius_se                569 non-null    float64\n"," 13  texture_se               569 non-null    float64\n"," 14  perimeter_se             569 non-null    float64\n"," 15  area_se                  569 non-null    float64\n"," 16  smoothness_se            569 non-null    float64\n"," 17  compactness_se           569 non-null    float64\n"," 18  concavity_se             569 non-null    float64\n"," 19  concave points_se        569 non-null    float64\n"," 20  symmetry_se              569 non-null    float64\n"," 21  fractal_dimension_se     569 non-null    float64\n"," 22  radius_worst             569 non-null    float64\n"," 23  texture_worst            569 non-null    float64\n"," 24  perimeter_worst          569 non-null    float64\n"," 25  area_worst               569 non-null    float64\n"," 26  smoothness_worst         569 non-null    float64\n"," 27  compactness_worst        569 non-null    float64\n"," 28  concavity_worst          569 non-null    float64\n"," 29  concave points_worst     569 non-null    float64\n"," 30  symmetry_worst           569 non-null    float64\n"," 31  fractal_dimension_worst  569 non-null    float64\n","dtypes: float64(30), int64(1), object(1)\n","memory usage: 142.4+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":331},"id":"qJbFshAdttYI","executionInfo":{"status":"ok","timestamp":1615293117711,"user_tz":-60,"elapsed":436,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"36c1f176-b645-4cf0-e161-b19720e266bf"},"source":["df.describe()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>symmetry_mean</th>\n","      <th>fractal_dimension_mean</th>\n","      <th>radius_se</th>\n","      <th>texture_se</th>\n","      <th>perimeter_se</th>\n","      <th>area_se</th>\n","      <th>smoothness_se</th>\n","      <th>compactness_se</th>\n","      <th>concavity_se</th>\n","      <th>concave points_se</th>\n","      <th>symmetry_se</th>\n","      <th>fractal_dimension_se</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.690000e+02</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","      <td>569.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>3.037183e+07</td>\n","      <td>14.127292</td>\n","      <td>19.289649</td>\n","      <td>91.969033</td>\n","      <td>654.889104</td>\n","      <td>0.096360</td>\n","      <td>0.104341</td>\n","      <td>0.088799</td>\n","      <td>0.048919</td>\n","      <td>0.181162</td>\n","      <td>0.062798</td>\n","      <td>0.405172</td>\n","      <td>1.216853</td>\n","      <td>2.866059</td>\n","      <td>40.337079</td>\n","      <td>0.007041</td>\n","      <td>0.025478</td>\n","      <td>0.031894</td>\n","      <td>0.011796</td>\n","      <td>0.020542</td>\n","      <td>0.003795</td>\n","      <td>16.269190</td>\n","      <td>25.677223</td>\n","      <td>107.261213</td>\n","      <td>880.583128</td>\n","      <td>0.132369</td>\n","      <td>0.254265</td>\n","      <td>0.272188</td>\n","      <td>0.114606</td>\n","      <td>0.290076</td>\n","      <td>0.083946</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.250206e+08</td>\n","      <td>3.524049</td>\n","      <td>4.301036</td>\n","      <td>24.298981</td>\n","      <td>351.914129</td>\n","      <td>0.014064</td>\n","      <td>0.052813</td>\n","      <td>0.079720</td>\n","      <td>0.038803</td>\n","      <td>0.027414</td>\n","      <td>0.007060</td>\n","      <td>0.277313</td>\n","      <td>0.551648</td>\n","      <td>2.021855</td>\n","      <td>45.491006</td>\n","      <td>0.003003</td>\n","      <td>0.017908</td>\n","      <td>0.030186</td>\n","      <td>0.006170</td>\n","      <td>0.008266</td>\n","      <td>0.002646</td>\n","      <td>4.833242</td>\n","      <td>6.146258</td>\n","      <td>33.602542</td>\n","      <td>569.356993</td>\n","      <td>0.022832</td>\n","      <td>0.157336</td>\n","      <td>0.208624</td>\n","      <td>0.065732</td>\n","      <td>0.061867</td>\n","      <td>0.018061</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>8.670000e+03</td>\n","      <td>6.981000</td>\n","      <td>9.710000</td>\n","      <td>43.790000</td>\n","      <td>143.500000</td>\n","      <td>0.052630</td>\n","      <td>0.019380</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.106000</td>\n","      <td>0.049960</td>\n","      <td>0.111500</td>\n","      <td>0.360200</td>\n","      <td>0.757000</td>\n","      <td>6.802000</td>\n","      <td>0.001713</td>\n","      <td>0.002252</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.007882</td>\n","      <td>0.000895</td>\n","      <td>7.930000</td>\n","      <td>12.020000</td>\n","      <td>50.410000</td>\n","      <td>185.200000</td>\n","      <td>0.071170</td>\n","      <td>0.027290</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.156500</td>\n","      <td>0.055040</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>8.692180e+05</td>\n","      <td>11.700000</td>\n","      <td>16.170000</td>\n","      <td>75.170000</td>\n","      <td>420.300000</td>\n","      <td>0.086370</td>\n","      <td>0.064920</td>\n","      <td>0.029560</td>\n","      <td>0.020310</td>\n","      <td>0.161900</td>\n","      <td>0.057700</td>\n","      <td>0.232400</td>\n","      <td>0.833900</td>\n","      <td>1.606000</td>\n","      <td>17.850000</td>\n","      <td>0.005169</td>\n","      <td>0.013080</td>\n","      <td>0.015090</td>\n","      <td>0.007638</td>\n","      <td>0.015160</td>\n","      <td>0.002248</td>\n","      <td>13.010000</td>\n","      <td>21.080000</td>\n","      <td>84.110000</td>\n","      <td>515.300000</td>\n","      <td>0.116600</td>\n","      <td>0.147200</td>\n","      <td>0.114500</td>\n","      <td>0.064930</td>\n","      <td>0.250400</td>\n","      <td>0.071460</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>9.060240e+05</td>\n","      <td>13.370000</td>\n","      <td>18.840000</td>\n","      <td>86.240000</td>\n","      <td>551.100000</td>\n","      <td>0.095870</td>\n","      <td>0.092630</td>\n","      <td>0.061540</td>\n","      <td>0.033500</td>\n","      <td>0.179200</td>\n","      <td>0.061540</td>\n","      <td>0.324200</td>\n","      <td>1.108000</td>\n","      <td>2.287000</td>\n","      <td>24.530000</td>\n","      <td>0.006380</td>\n","      <td>0.020450</td>\n","      <td>0.025890</td>\n","      <td>0.010930</td>\n","      <td>0.018730</td>\n","      <td>0.003187</td>\n","      <td>14.970000</td>\n","      <td>25.410000</td>\n","      <td>97.660000</td>\n","      <td>686.500000</td>\n","      <td>0.131300</td>\n","      <td>0.211900</td>\n","      <td>0.226700</td>\n","      <td>0.099930</td>\n","      <td>0.282200</td>\n","      <td>0.080040</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>8.813129e+06</td>\n","      <td>15.780000</td>\n","      <td>21.800000</td>\n","      <td>104.100000</td>\n","      <td>782.700000</td>\n","      <td>0.105300</td>\n","      <td>0.130400</td>\n","      <td>0.130700</td>\n","      <td>0.074000</td>\n","      <td>0.195700</td>\n","      <td>0.066120</td>\n","      <td>0.478900</td>\n","      <td>1.474000</td>\n","      <td>3.357000</td>\n","      <td>45.190000</td>\n","      <td>0.008146</td>\n","      <td>0.032450</td>\n","      <td>0.042050</td>\n","      <td>0.014710</td>\n","      <td>0.023480</td>\n","      <td>0.004558</td>\n","      <td>18.790000</td>\n","      <td>29.720000</td>\n","      <td>125.400000</td>\n","      <td>1084.000000</td>\n","      <td>0.146000</td>\n","      <td>0.339100</td>\n","      <td>0.382900</td>\n","      <td>0.161400</td>\n","      <td>0.317900</td>\n","      <td>0.092080</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>9.113205e+08</td>\n","      <td>28.110000</td>\n","      <td>39.280000</td>\n","      <td>188.500000</td>\n","      <td>2501.000000</td>\n","      <td>0.163400</td>\n","      <td>0.345400</td>\n","      <td>0.426800</td>\n","      <td>0.201200</td>\n","      <td>0.304000</td>\n","      <td>0.097440</td>\n","      <td>2.873000</td>\n","      <td>4.885000</td>\n","      <td>21.980000</td>\n","      <td>542.200000</td>\n","      <td>0.031130</td>\n","      <td>0.135400</td>\n","      <td>0.396000</td>\n","      <td>0.052790</td>\n","      <td>0.078950</td>\n","      <td>0.029840</td>\n","      <td>36.040000</td>\n","      <td>49.540000</td>\n","      <td>251.200000</td>\n","      <td>4254.000000</td>\n","      <td>0.222600</td>\n","      <td>1.058000</td>\n","      <td>1.252000</td>\n","      <td>0.291000</td>\n","      <td>0.663800</td>\n","      <td>0.207500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n","count  5.690000e+02   569.000000  ...      569.000000               569.000000\n","mean   3.037183e+07    14.127292  ...        0.290076                 0.083946\n","std    1.250206e+08     3.524049  ...        0.061867                 0.018061\n","min    8.670000e+03     6.981000  ...        0.156500                 0.055040\n","25%    8.692180e+05    11.700000  ...        0.250400                 0.071460\n","50%    9.060240e+05    13.370000  ...        0.282200                 0.080040\n","75%    8.813129e+06    15.780000  ...        0.317900                 0.092080\n","max    9.113205e+08    28.110000  ...        0.663800                 0.207500\n","\n","[8 rows x 31 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"puQCMWE0fK0S"},"source":["Creiamo gli array numpy per addestrare e testare la nostra rete neurale."]},{"cell_type":"markdown","metadata":{"id":"1fhe6N7O2Obp"},"source":["## Target= diagnosis -- binary classes"]},{"cell_type":"code","metadata":{"id":"Uwxv9QG1fK0T","executionInfo":{"status":"ok","timestamp":1615293119311,"user_tz":-60,"elapsed":907,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["X = df.drop(['diagnosis','id'],axis=1).values\n","y = df['diagnosis'].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=667)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t8EurPkAfK0T"},"source":["Codifichiamo i label della nostra variabile target in numeri."]},{"cell_type":"code","metadata":{"id":"OVa9qF3VfK0T","executionInfo":{"status":"ok","timestamp":1615293120435,"user_tz":-60,"elapsed":891,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["le = LabelEncoder()\n","y_train = le.fit_transform(y_train)\n","y_test = le.transform(y_test)"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PCHQjN9yfK0T"},"source":["Standardizziamo gli array con le features."]},{"cell_type":"code","metadata":{"id":"4kttWFNjfK0T","executionInfo":{"status":"ok","timestamp":1615293120640,"user_tz":-60,"elapsed":379,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["ss = StandardScaler()\n","X_train = ss.fit_transform(X_train)\n","X_test = ss.transform(X_test)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjuN5BHMfK0U","executionInfo":{"status":"ok","timestamp":1615293121461,"user_tz":-60,"elapsed":791,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"8d1ec690-a0bd-4fb5-99c9-f5caaf52fd24"},"source":["X_train.shape"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(398, 30)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"9gwcbmYPfK0U"},"source":["Adesso possiamo passare alla costruzione della nostra rete neurale artificiale, il primo modello che andremo a creare sarà così composto:\n","* **30 nodi** nello strato di input, pari al numero di features del dataset.\n","* **12 nodi** nello strato nascosto, numero scelto arbitrariamente da noi. \n","* **1 nodo** nello strato di output, dato che si tratta di una classificazione binaria.\n","\n","La funzione di attivazione che utilizzeremo per lo strato nascosto è la **ReLU**, mentre, trattandosi di un problema di classificazione binaria, per lo strato di output utilizzeremo la sigmoide. [Qui](https://keras.io/activations/) puoi vedere l'elenco completo delle **funzioni di attivazione di base** disponibili con Keras."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLkjZZpN4_G6","executionInfo":{"status":"ok","timestamp":1615293122168,"user_tz":-60,"elapsed":657,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"32c9f7b7-08f2-4a92-d2f4-3c64ddda5383"},"source":["X_train.shape[1]"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"acf8pCvjfK0U","executionInfo":{"status":"ok","timestamp":1615293122901,"user_tz":-60,"elapsed":940,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["import tensorflow as tf\n","tf.random.set_seed(667) \n","\n","model = Sequential()\n","model.add(Dense(12, input_dim=X_train.shape[1], activation=\"relu\"))\n","model.add(Dense(1, activation=\"sigmoid\"))"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wVWo22a1fK0U"},"source":["Utilizziamo il metodo compile per configurare la fase di addestramento, specificando come funzione di ottimizzazione lo **Stochastic Gradient Descent** come funzione da minimizzare la **binary cross entropy** e aggiungiamo come metrica aggiuntiva da visualizzare durante il training l'**accuracy**."]},{"cell_type":"code","metadata":{"id":"ArnFjI2sfK0V","executionInfo":{"status":"ok","timestamp":1615293123727,"user_tz":-60,"elapsed":566,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KZ_22ln-fK0V"},"source":["Utilizziamo il metodo summary per osservare il numero di parametri totali che la nostra rete dovrà ottimizzare."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJ-YN5hufK0V","executionInfo":{"status":"ok","timestamp":1615293124863,"user_tz":-60,"elapsed":386,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"0d45c30e-4ec4-4425-8079-3bc3d8ef223f"},"source":["model.summary()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_4 (Dense)              (None, 12)                372       \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 13        \n","=================================================================\n","Total params: 385\n","Trainable params: 385\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_xxynr9zfK0V"},"source":["Abbiamo 385 parametri in totale:\n","* 1 - Un peso per ogni connessione dai 30 nodi di input ai 12 nodi dell' hidden layer (30x12=360), più un bias per ogni nodonell'hidden layer (12). =360+12\n","* 2 - Un peso per ogni connessione dell'hidden layer all'unico nodo dello strato di output (12), più un bias (1)"]},{"cell_type":"markdown","metadata":{"id":"hxj4pJiafK0V"},"source":["Facciamo partire l'addestramento."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDhWs7W4fK0W","executionInfo":{"status":"ok","timestamp":1615293130186,"user_tz":-60,"elapsed":4045,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"99e43796-3a16-4edc-a7b9-698386fa98b8"},"source":["model.fit(X_train, y_train, epochs=100)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","13/13 [==============================] - 1s 2ms/step - loss: 0.9760 - accuracy: 0.3264\n","Epoch 2/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.7588 - accuracy: 0.4565\n","Epoch 3/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6331\n","Epoch 4/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7773\n","Epoch 5/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8017\n","Epoch 6/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.8902\n","Epoch 7/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8865\n","Epoch 8/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.9149\n","Epoch 9/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.9132\n","Epoch 10/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.9399\n","Epoch 11/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.9458\n","Epoch 12/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.9583\n","Epoch 13/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2517 - accuracy: 0.9549\n","Epoch 14/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9586\n","Epoch 15/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9553\n","Epoch 16/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9560\n","Epoch 17/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9614\n","Epoch 18/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9654\n","Epoch 19/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.9594\n","Epoch 20/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.9666\n","Epoch 21/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9621\n","Epoch 22/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9715\n","Epoch 23/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9768\n","Epoch 24/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9671\n","Epoch 25/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9787\n","Epoch 26/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9680\n","Epoch 27/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9791\n","Epoch 28/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9731\n","Epoch 29/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9734\n","Epoch 30/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9808\n","Epoch 31/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1270 - accuracy: 0.9720\n","Epoch 32/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.9647\n","Epoch 33/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9722\n","Epoch 34/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9768\n","Epoch 35/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.9771\n","Epoch 36/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9708\n","Epoch 37/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9637\n","Epoch 38/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9791\n","Epoch 39/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9829\n","Epoch 40/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9753\n","Epoch 41/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9833\n","Epoch 42/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9765\n","Epoch 43/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9750\n","Epoch 44/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9688\n","Epoch 45/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9602\n","Epoch 46/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9687\n","Epoch 47/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9753\n","Epoch 48/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9734\n","Epoch 49/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9695\n","Epoch 50/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9773\n","Epoch 51/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9728\n","Epoch 52/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9765\n","Epoch 53/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9728\n","Epoch 54/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9758\n","Epoch 55/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9754\n","Epoch 56/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9668\n","Epoch 57/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0874 - accuracy: 0.9812\n","Epoch 58/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9755\n","Epoch 59/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9818\n","Epoch 60/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0818 - accuracy: 0.9802\n","Epoch 61/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9719\n","Epoch 62/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9785\n","Epoch 63/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9679\n","Epoch 64/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9771\n","Epoch 65/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9811\n","Epoch 66/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9719\n","Epoch 67/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9820\n","Epoch 68/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9778\n","Epoch 69/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9648\n","Epoch 70/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9746\n","Epoch 71/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9662\n","Epoch 72/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9729\n","Epoch 73/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9763\n","Epoch 74/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.9755\n","Epoch 75/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9713\n","Epoch 76/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9662\n","Epoch 77/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9713\n","Epoch 78/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9755\n","Epoch 79/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9759\n","Epoch 80/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9761\n","Epoch 81/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9786\n","Epoch 82/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9828\n","Epoch 83/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9730\n","Epoch 84/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9741\n","Epoch 85/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0784 - accuracy: 0.9752\n","Epoch 86/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9809\n","Epoch 87/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9800\n","Epoch 88/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9717\n","Epoch 89/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9746\n","Epoch 90/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9814\n","Epoch 91/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0609 - accuracy: 0.9819\n","Epoch 92/100\n","13/13 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9762\n","Epoch 93/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.9809\n","Epoch 94/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 0.9827\n","Epoch 95/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9806\n","Epoch 96/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9800\n","Epoch 97/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9853\n","Epoch 98/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9745\n","Epoch 99/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9705\n","Epoch 100/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9900\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f743bda36d0>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"PqcR2pUXfK0W"},"source":["All'epoca 100 il nostro modello ha ottenuto sul set di addestramento un'accuracy del 98% e un valore per la funzione di costo di 0.082, verifichiamo il risultato anche sul set di test."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWuEjXLnfK0W","executionInfo":{"status":"ok","timestamp":1615293131093,"user_tz":-60,"elapsed":1350,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"7c4c9473-67a0-4551-9f1d-4b5161bcc9e3"},"source":["loss, acc = model.evaluate(X_test, y_test)\n","print(\"Loss sul test set: %.4f\" % loss)\n","print(\"Accuracy sul test set: %.4f\" % acc)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["6/6 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9766\n","Loss sul test set: 0.1044\n","Accuracy sul test set: 0.9766\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ntMi_gmCfK0W"},"source":["Confrontando il risultato con quanto fatto in [questo precedente notebook](https://github.com/ProfAI/dl00/blob/master/3%20-%20Machine%20Learning%20in%20breve/Regressione%20logistica%20con%20Keras.ipynb), possiamo osservare come una rete neurale artificiale abbia portanto un risultato migliore rispetto a una semplice regressione logistica, specialmente per quanto riguarda l'incertezza dell'errore."]},{"cell_type":"markdown","metadata":{"id":"7-JFN0xpfK0W"},"source":["## Reti neurali artificiali profonde\n","Adesso proviamo a costruire una rete neurale artificiale profonda, cioè una rete neurale che ha più di uno strato nascosto, nello specifica la nostra rete neurale profonda sarà così composta:\n","* **30 nodi** nello strato di input\n","* **12 nodi** nel primo strato nascosto\n","* **8 nodi** nel secondo strato nascosto\n","* **4 nodi** nel secondo strato nascosto\n","* **1 nodo** nello strato di input\n","\n","Come funzione di attivazione utilizzeremo sempre la ReLU per gli strati nascosti e la sigmoide per lo strato di output."]},{"cell_type":"code","metadata":{"id":"-0Mon0fXfK0X","executionInfo":{"status":"ok","timestamp":1615293131831,"user_tz":-60,"elapsed":343,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["tf.random.set_seed(667) \n","model = Sequential()\n","\n","model.add(Dense(12, input_dim=X_train.shape[1], activation=\"relu\"))\n","model.add(Dense(8, activation=\"relu\"))\n","model.add(Dense(4, activation=\"relu\"))\n","model.add(Dense(1, activation=\"sigmoid\"))\n","\n","model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JxSg_kDbfK0X"},"source":["Utilizziamo il metodo summary per osservare quanti parametri dovrà ottimizzare il nostro modello questa volta."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KgK7iW2LfK0X","executionInfo":{"status":"ok","timestamp":1615293135054,"user_tz":-60,"elapsed":368,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"4af7d343-abbf-4827-c271-dd69f0334331"},"source":["model.summary()"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_6 (Dense)              (None, 12)                372       \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 8)                 104       \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 4)                 36        \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 5         \n","=================================================================\n","Total params: 517\n","Trainable params: 517\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HrUSb5kVfK0X"},"source":["Adesso son ben 517, facciamo partire l'addestramento."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAiCthv0fK0X","executionInfo":{"status":"ok","timestamp":1615293145422,"user_tz":-60,"elapsed":3746,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"dd0909ab-f564-432b-d2cb-ca967b386b7b"},"source":["model.fit(X_train, y_train, epochs=100)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.4449\n","Epoch 2/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5817\n","Epoch 3/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6424\n","Epoch 4/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.7296\n","Epoch 5/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.7603\n","Epoch 6/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.7950\n","Epoch 7/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.8287\n","Epoch 8/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.8279\n","Epoch 9/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.8533\n","Epoch 10/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.5436 - accuracy: 0.8801\n","Epoch 11/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.9065\n","Epoch 12/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.9157\n","Epoch 13/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.9250\n","Epoch 14/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.9108\n","Epoch 15/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.9137\n","Epoch 16/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.9071\n","Epoch 17/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.9301\n","Epoch 18/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.9176\n","Epoch 19/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.9234\n","Epoch 20/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.9352\n","Epoch 21/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.9222\n","Epoch 22/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.9376\n","Epoch 23/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.9391\n","Epoch 24/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.9280\n","Epoch 25/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.9371\n","Epoch 26/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.9381\n","Epoch 27/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.9514\n","Epoch 28/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.9492\n","Epoch 29/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.9449\n","Epoch 30/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.9457\n","Epoch 31/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.9531\n","Epoch 32/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.9428\n","Epoch 33/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.9582\n","Epoch 34/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.9614\n","Epoch 35/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3123 - accuracy: 0.9569\n","Epoch 36/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.9574\n","Epoch 37/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.9431\n","Epoch 38/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.9565\n","Epoch 39/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2817 - accuracy: 0.9697\n","Epoch 40/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.9615\n","Epoch 41/100\n","13/13 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.9718\n","Epoch 42/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9533\n","Epoch 43/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.9686\n","Epoch 44/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.9608\n","Epoch 45/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2802 - accuracy: 0.9495\n","Epoch 46/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9563\n","Epoch 47/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2660 - accuracy: 0.9580\n","Epoch 48/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.9652\n","Epoch 49/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2633 - accuracy: 0.9437\n","Epoch 50/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.9623\n","Epoch 51/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9607\n","Epoch 52/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2514 - accuracy: 0.9611\n","Epoch 53/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9605\n","Epoch 54/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9678\n","Epoch 55/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9634\n","Epoch 56/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9507\n","Epoch 57/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9637\n","Epoch 58/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9691\n","Epoch 59/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9720\n","Epoch 60/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9681\n","Epoch 61/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9680\n","Epoch 62/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9593\n","Epoch 63/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9627\n","Epoch 64/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.9716\n","Epoch 65/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2030 - accuracy: 0.9750\n","Epoch 66/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9682\n","Epoch 67/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9758\n","Epoch 68/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9668\n","Epoch 69/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9572\n","Epoch 70/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9678\n","Epoch 71/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9607\n","Epoch 72/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9611\n","Epoch 73/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.9675\n","Epoch 74/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9624\n","Epoch 75/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9571\n","Epoch 76/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9536\n","Epoch 77/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9691\n","Epoch 78/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9661\n","Epoch 79/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9705\n","Epoch 80/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.9584\n","Epoch 81/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9656\n","Epoch 82/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1603 - accuracy: 0.9768\n","Epoch 83/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9622\n","Epoch 84/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9767\n","Epoch 85/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9680\n","Epoch 86/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9709\n","Epoch 87/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9684\n","Epoch 88/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9701\n","Epoch 89/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9674\n","Epoch 90/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9786\n","Epoch 91/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9752\n","Epoch 92/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9695\n","Epoch 93/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9721\n","Epoch 94/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9772\n","Epoch 95/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9694\n","Epoch 96/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9780\n","Epoch 97/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9734\n","Epoch 98/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9789\n","Epoch 99/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9668\n","Epoch 100/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9904\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f743ab768d0>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"46_UAGA9fK0Y"},"source":["All'epoca 100 il nostro modello ha ottenuto sul set di addestramento un'accuracy del 99% e un valore per la funzione di costo di 0.14, verifichiamo il risultato anche sul set di test."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDh5ijiHfK0Y","executionInfo":{"status":"ok","timestamp":1615293168679,"user_tz":-60,"elapsed":858,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"c44f60e1-094d-45ba-aaa2-68007c10efb8"},"source":["loss, acc = model.evaluate(X_test, y_test)\n","print(\"Loss sul test set: %.4f\" % loss)\n","print(\"Accuracy sul test set: %.4f\" % acc)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["6/6 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9591\n","Loss sul test set: 0.1748\n","Accuracy sul test set: 0.9591\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hGy8o_YGfK0Y"},"source":["Aggiungendo due nuovi strati le performance della nostra rete sono migliorate."]},{"cell_type":"markdown","metadata":{"id":"sn9cS-eIfK0Y"},"source":["## Leaky ReLU\n","Reimplentiamo lo stesso modello, questa volta utilizzando la Leaky ReLU come funzione di attivazione per gli strati nascosti. La Leaky ReLU fa parte delle **funzioni di attivazioni avanzate** di Keras, che puoi trovare [qui](https://keras.io/layers/advanced-activations/).\n","<br>\n","Queste funzioni di attivazioni vanno aggiunte a un modello come fossero degli strati e non passate come parametro della classe Dense, come invece fatto finora."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fw8hVF1sfK0Z","executionInfo":{"status":"ok","timestamp":1615293213154,"user_tz":-60,"elapsed":3675,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"ac48b63f-1c85-45df-84ab-895f257cfa9b"},"source":["tf.random.set_seed(667) \n","from keras.layers import LeakyReLU\n","\n","model = Sequential()\n","\n","model.add(Dense(12, input_dim=X_train.shape[1]))\n","model.add(LeakyReLU(alpha=0.01))\n","model.add(Dense(4))\n","model.add(LeakyReLU(alpha=0.01))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n","model.fit(X_train, y_train, epochs=100)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.6316\n","Epoch 2/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.6097 - accuracy: 0.6677\n","Epoch 3/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.6836\n","Epoch 4/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.6824\n","Epoch 5/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7254\n","Epoch 6/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7480\n","Epoch 7/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7645\n","Epoch 8/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.8005\n","Epoch 9/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7941\n","Epoch 10/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8491\n","Epoch 11/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8273\n","Epoch 12/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8327\n","Epoch 13/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8881\n","Epoch 14/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8752\n","Epoch 15/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8906\n","Epoch 16/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.9091\n","Epoch 17/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.9083\n","Epoch 18/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.9102\n","Epoch 19/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.9031\n","Epoch 20/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.9063\n","Epoch 21/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.9022\n","Epoch 22/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.9264\n","Epoch 23/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.9348\n","Epoch 24/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.9317\n","Epoch 25/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.9253\n","Epoch 26/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.9369\n","Epoch 27/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9513\n","Epoch 28/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.9360\n","Epoch 29/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.9442\n","Epoch 30/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2861 - accuracy: 0.9473\n","Epoch 31/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.9438\n","Epoch 32/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.9534\n","Epoch 33/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.9520\n","Epoch 34/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.9493\n","Epoch 35/100\n","13/13 [==============================] - 0s 3ms/step - loss: 0.2683 - accuracy: 0.9493\n","Epoch 36/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.9496\n","Epoch 37/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.9391\n","Epoch 38/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.9592\n","Epoch 39/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9573\n","Epoch 40/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9555\n","Epoch 41/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.9627\n","Epoch 42/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9622\n","Epoch 43/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.9577\n","Epoch 44/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9650\n","Epoch 45/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.9523\n","Epoch 46/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9619\n","Epoch 47/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9735\n","Epoch 48/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.9565\n","Epoch 49/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2403 - accuracy: 0.9482\n","Epoch 50/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9580\n","Epoch 51/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9584\n","Epoch 52/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9543\n","Epoch 53/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9576\n","Epoch 54/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9613\n","Epoch 55/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.9563\n","Epoch 56/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9587\n","Epoch 57/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.9511\n","Epoch 58/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9787\n","Epoch 59/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.9688\n","Epoch 60/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9689\n","Epoch 61/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.9545\n","Epoch 62/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9525\n","Epoch 63/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.9621\n","Epoch 64/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9695\n","Epoch 65/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9672\n","Epoch 66/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9616\n","Epoch 67/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9781\n","Epoch 68/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9555\n","Epoch 69/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.9594\n","Epoch 70/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9688\n","Epoch 71/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9630\n","Epoch 72/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9723\n","Epoch 73/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9726\n","Epoch 74/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.9752\n","Epoch 75/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.9724\n","Epoch 76/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9613\n","Epoch 77/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9692\n","Epoch 78/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9540\n","Epoch 79/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9733\n","Epoch 80/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.9786\n","Epoch 81/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9752\n","Epoch 82/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9847\n","Epoch 83/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9771\n","Epoch 84/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9714\n","Epoch 85/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1731 - accuracy: 0.9654\n","Epoch 86/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1538 - accuracy: 0.9834\n","Epoch 87/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9694\n","Epoch 88/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9674\n","Epoch 89/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9704\n","Epoch 90/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.9763\n","Epoch 91/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1550 - accuracy: 0.9801\n","Epoch 92/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9679\n","Epoch 93/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1667 - accuracy: 0.9625\n","Epoch 94/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9787\n","Epoch 95/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9771\n","Epoch 96/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9759\n","Epoch 97/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9783\n","Epoch 98/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9633\n","Epoch 99/100\n","13/13 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9688\n","Epoch 100/100\n","13/13 [==============================] - 0s 1ms/step - loss: 0.1445 - accuracy: 0.9750\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f743aa20250>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gof8nRLYfK0Z","executionInfo":{"status":"ok","timestamp":1615293214352,"user_tz":-60,"elapsed":712,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"c5149391-b5d2-4754-bb35-1cee4be0a166"},"source":["loss, acc = model.evaluate(X_test, y_test)\n","print(\"Loss sul test set: %.4f\" % loss)\n","print(\"Accuracy sul test set: %.4f\" % acc)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["6/6 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9766\n","Loss sul test set: 0.1813\n","Accuracy sul test set: 0.9766\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5K9L485lfK0Z"},"source":["L'utilizzo della funzione Leaky ReLU ci ha permesso di ottenere un modello ancora migliore."]},{"cell_type":"markdown","metadata":{"id":"Y4OQtgHYfK0Z"},"source":["### Matrice di confusione\n","Nonostante le metriche della nostra rete neurale artificiale siano molto buone, dobbiamo tener conto du un ulteriore fattore. Quando si tratta di riconoscere un tumore, sbagliare nel diagnosticare un tumore maligno come benigno è molto più grave del classificare un tuomore benigno come maligno, infatti in quest'ultimo caso l'errore potrebbe venir fuori dopo ulteriori indagini mediche, mentre nel primo il paziente potrebbe non ricevere cure mediche necessarie per lui a causa dell'errore.\n","<br><br>\n","Questo problema è comune in molti problemi di classificazione, per affronterlo ci viene in contro una nuova metrica: la matrice di confusione.\n","<br>\n","La matrice di confusione ci permette di comprendere dove il nostro modello ha commesso degli errori.\n","<br><br>\n","Creiamo una matrice di confusione utilizzando la funzione <span style=\"font-family: Monaco\">plot_confusion_matrix</span> disponibile all'interno del modulo <span style=\"font-family: Monaco\">viz</span>.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":538},"id":"X-4_H2w4fK0Z","executionInfo":{"status":"ok","timestamp":1615293293748,"user_tz":-60,"elapsed":757,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"299011ee-baa3-4e59-9eb8-4f2bf59f0ffa"},"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12,8))\n","y_pred = model.predict_classes(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","labels = ['benigno','maligno']\n","sns.heatmap(cm,xticklabels=labels,yticklabels=labels,annot=True,fmt=\".0f\",cmap='viridis');\n"],"execution_count":40,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"4UiYU9FLfK0a"},"source":["Osservando la matrice di confusione possiamo vedere che:\n","1. La rete ha correttamente classificato 108 tumori benigni su 109.\n","2. La rete ha correttamente classificato 59 tumori maligni su 62\n","3. La rete ha confuso 3 tumori maligni come tumori benigni.\n","4. La rete ha confuso 1 tumori benigno come tumore maligno."]},{"cell_type":"code","metadata":{"id":"zu5kAlHhvEig","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615293309239,"user_tz":-60,"elapsed":613,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"d7d34768-25aa-4ead-924d-608c60b71190"},"source":["from sklearn.metrics import classification_report\r\n","print(classification_report(y_test,y_pred))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.97      0.99      0.98       109\n","           1       0.98      0.95      0.97        62\n","\n","    accuracy                           0.98       171\n","   macro avg       0.98      0.97      0.97       171\n","weighted avg       0.98      0.98      0.98       171\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":621},"id":"aML1h4Zp_BNa","executionInfo":{"status":"ok","timestamp":1615293931823,"user_tz":-60,"elapsed":833,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"fb46cc87-6536-424b-e514-d3d4b87a097b"},"source":["from sklearn.metrics import roc_curve, auc\r\n","y_pred = model.predict(X_test).ravel() #flatten array\r\n","\r\n","plt.figure(figsize=(12,10))\r\n","\r\n","nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(y_test, y_pred)\r\n","auc_keras = auc(nn_fpr_keras, nn_tpr_keras)\r\n","plt.plot(nn_fpr_keras, nn_tpr_keras, marker='*', label='Neural Network (auc = %0.3f)' % auc_keras);\r\n","\r\n","# Title\r\n","plt.title('ROC CURVE Plot')\r\n","\r\n","#Axis labels\r\n","plt.xlabel('False Positive Rate')\r\n","plt.ylabel('True Positive Rate')\r\n","\r\n","#Legend\r\n","plt.legend();"],"execution_count":61,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x720 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"wrQi8S3xt5GM","executionInfo":{"status":"ok","timestamp":1615294429149,"user_tz":-60,"elapsed":495,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["from sklearn.preprocessing import MinMaxScaler\r\n","from tensorflow.keras.models import load_model"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHtJH6Lyt_Qw","executionInfo":{"status":"ok","timestamp":1615294431083,"user_tz":-60,"elapsed":607,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["model.save('breast_cancer.h5') "],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"hI3v5Rdot_5K","executionInfo":{"status":"ok","timestamp":1615294432954,"user_tz":-60,"elapsed":620,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["load_model = load_model('breast_cancer.h5')"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lJfwc1m7uAV0","executionInfo":{"status":"ok","timestamp":1615294436308,"user_tz":-60,"elapsed":905,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"08cfd580-db01-40d0-e455-a21620823bbb"},"source":["# [[Feature1, Feature2....,Feature[30]]]\r\n","new_sample = [[1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10]]\r\n","len(new_sample[0])"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"9Q5vs7fauAYm","executionInfo":{"status":"ok","timestamp":1615294438756,"user_tz":-60,"elapsed":704,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["scaler = MinMaxScaler()\r\n","new_sample_scaled = scaler.fit_transform(new_sample)"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tYk3Rfd6E1ER","executionInfo":{"status":"ok","timestamp":1615294846510,"user_tz":-60,"elapsed":641,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"80f5b76a-4558-4a10-9939-8cde4eb62664"},"source":["load_model.predict(new_sample_scaled)"],"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.5794424]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_dHOwYsDYtP","executionInfo":{"status":"ok","timestamp":1615294847294,"user_tz":-60,"elapsed":344,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"d8b601bb-c964-4c18-fe31-ebc89fc02819"},"source":["input = np.where((load_model.predict(new_sample_scaled))> 0.5, 1, 0)\r\n","input"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1]])"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"id":"OgSJ52sHuAi8","executionInfo":{"status":"ok","timestamp":1615294865958,"user_tz":-60,"elapsed":578,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["def pred(x):\r\n","    if x==1:\r\n","        return 'benigno'\r\n","    else:\r\n","        return 'maligno'"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8ngk0HQjrdf8","executionInfo":{"status":"ok","timestamp":1615294868167,"user_tz":-60,"elapsed":693,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}},"outputId":"9622e84b-8a3e-44da-f994-44b7baf05f52"},"source":["pred(input)"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'benigno'"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"kjsoqEQfE707"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"81nIWbWKrgD9","executionInfo":{"status":"ok","timestamp":1615295255414,"user_tz":-60,"elapsed":624,"user":{"displayName":"T3Lab Vision","photoUrl":"","userId":"14779383426442114373"}}},"source":["##if multiclass:\r\n","#prediction = load_model.predict(new_sample_scaled)\r\n","#predict_label=np.argmax(prediction,axis=1)"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"GryynTgkFKmp"},"source":[""],"execution_count":null,"outputs":[]}]}