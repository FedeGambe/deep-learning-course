{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-Intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visiont3lab/deep-learning-course/blob/main/colab/Pytorch_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKcyjqN2jhzF"
      },
      "source": [
        "# Pytorch Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUpnbbI3jrQd"
      },
      "source": [
        "## Pytorch setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNjKSYqb7_PD"
      },
      "source": [
        "* Local (Own Pc)\n",
        "\n",
        "    Install [python 3.8](https://www.python.org/downloads/)\n",
        "\n",
        "    ```\n",
        "    pip3 install virtualenv\n",
        "    virtualenv env\n",
        "    source env/bin/activate # Linux - Mac\n",
        "    source env/Scripts/activate # Windows\n",
        "    pip install torch torchvision\n",
        "    ```\n",
        "\n",
        "\n",
        "* Google Colab\n",
        "\n",
        "    ```\n",
        "    pip3 install torch torchvision\n",
        "    ```\n",
        "These requirements should be arealdy satisied\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEIaS-Q8tSI-",
        "outputId": "61c954e8-4c0e-41c3-bc06-f79c12ab225e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar  4 19:26:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tH0Ck6L5kTQ",
        "outputId": "ce7f881c-0717-4cd0-f670-77392b6058e3"
      },
      "source": [
        "# Verify installation\n",
        "!pip list | grep torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch                         1.7.1+cu101   \n",
            "torchsummary                  1.5.1         \n",
            "torchtext                     0.3.1         \n",
            "torchvision                   0.8.2+cu101   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2rHdZ4a9Gl9",
        "outputId": "26800e0e-4d54-4038-ebde-bb7b90c4ec5f"
      },
      "source": [
        "# Change runtime colab type to enable GPU\n",
        "# Click on Runtime --> Select Change Runtime Type --> Select Hardware Accelarion GPU\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "print(\"Torch Version: \",torch.__version__)\n",
        "print(\"Torch Vision Version:\", torchvision.__version__)\n",
        "print(\"Is Cuda available: \", torch.cuda.is_available())\n",
        "print(\"Number of  Cuda device: \", torch.cuda.device_count())\n",
        "print(\"Get Cuda Current device: \", torch.cuda.current_device())\n",
        "print(\"Get Name of Cuda  device: \", torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch Version:  1.7.1+cu101\n",
            "Torch Vision Version: 0.8.2+cu101\n",
            "Is Cuda available:  True\n",
            "Number of  Cuda device:  1\n",
            "Get Cuda Current device:  0\n",
            "Get Name of Cuda  device:  Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgrFTeOYvWdV",
        "outputId": "10656de9-5db4-4a20-e067-0ca849fb6395"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvzvvjNRKF5b",
        "outputId": "fd044815-c9ac-4f78-b06a-b5a908fd8622"
      },
      "source": [
        "! pip3 install torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.7.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.8.2+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV3_nBpi_YJ5"
      },
      "source": [
        "## Pytorch: Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERI7NZCk_dIu"
      },
      "source": [
        "> Tensor: n-dimensional array\n",
        "\n",
        "* [Pytoch documentation](https://pytorch.org/docs/stable/index.html)\n",
        "* [List of Pytorch Type](https://pytorch.org/docs/stable/tensors.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Daxr3q3798gv",
        "outputId": "70e326b6-c063-4d4b-fc12-38afd4228138"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "x = torch.ones((4,4), dtype=torch.float16)\n",
        "#x = np.ones((4,4), dtype=np.float16)\n",
        "print(x)\n",
        "print(\"Shape: \", x.shape)\n",
        "print(\"Type : \", x.dtype) # Torch default data type is torch.float32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], dtype=torch.float16)\n",
            "Shape:  torch.Size([4, 4])\n",
            "Type :  torch.float16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSM5NQafADMj",
        "outputId": "428690a0-b72a-4401-d1ca-5abcfcc9786e"
      },
      "source": [
        "# Specify tensor type\n",
        "x = 2*torch.ones((1,3,2), dtype=torch.int8)\n",
        "print(x)\n",
        "print(\"Shape: \", x.shape)\n",
        "print(\"Type : \", x.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[2, 2],\n",
            "         [2, 2],\n",
            "         [2, 2]]], dtype=torch.int8)\n",
            "Shape:  torch.Size([1, 3, 2])\n",
            "Type :  torch.int8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyLARNB4AjiJ",
        "outputId": "3427bf42-921e-41be-fa46-4335c5271971"
      },
      "source": [
        "# Change tensor type\n",
        "x = torch.rand(3, dtype=torch.float32) # random uniform 0-1\n",
        "x = 5*x # Multiply by 5\n",
        "print(\"Tensor: %s , Type: %s \" % (x, x.dtype))\n",
        "x = x.type(torch.uint8) # change data type to unit8\n",
        "print(\"Tensor: %s , Type: %s \" % (x, x.dtype))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor: tensor([3.8648, 3.3090, 3.7264]) , Type: torch.float32 \n",
            "Tensor: tensor([3, 3, 3], dtype=torch.uint8) , Type: torch.uint8 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb-gH_3EBFAC",
        "outputId": "76ecacc9-ad40-4cfe-cfda-33cf9bfa3532"
      },
      "source": [
        "# Tensor to numpy array\n",
        "x = torch.sin( torch.rand(4) + 2*torch.rand(4) )\n",
        "xnp = x.numpy()\n",
        "print(\"Numpy Array: %s , Type: %s \" % (xnp, xnp.dtype))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numpy Array: [0.9982301 0.6028976 0.7176252 0.8889904] , Type: float32 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QNpDjIwCPlK",
        "outputId": "6d36a8dc-5d49-455c-f69f-caf98527d547"
      },
      "source": [
        "# Numpy array to tensor\n",
        "import numpy as np\n",
        "xnp = np.sin( np.random.rand(4) + 2*np.random.rand(4) ) # Float64 by default numpy\n",
        "print(xnp)\n",
        "x = torch.from_numpy(xnp)\n",
        "x = x.type(torch.float32)\n",
        "print(\"Tensor: %s , Type: %s \" % (x, x.dtype))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.87555113 0.62579561 0.79933828 0.97127132]\n",
            "Tensor: tensor([0.8756, 0.6258, 0.7993, 0.9713]) , Type: torch.float32 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEN8ncC-CsCK",
        "outputId": "bea1eec2-0539-4723-da88-2817a33f44e9"
      },
      "source": [
        "# Moving tensor bettwen cpu and cuda device\n",
        "# If u do not specify the device the tensorf will be hosted by default on cpu\n",
        "x = torch.tensor([[1,3,4.4,5.6]]) # RAM\n",
        "print(\"Tensor: %s , Type: %s ,Shape: %s, Device: %s\" % (x.tolist(), x.dtype,x.shape,x.device))\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    x = x.to(device)\n",
        "    print(\"Tensor: %s , Type: %s ,Shape: %s, Device: %s\" % (x.tolist(), x.dtype,x.shape,x.device))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor: [[1.0, 3.0, 4.400000095367432, 5.599999904632568]] , Type: torch.float32 ,Shape: torch.Size([1, 4]), Device: cpu\n",
            "Tensor: [[1.0, 3.0, 4.400000095367432, 5.599999904632568]] , Type: torch.float32 ,Shape: torch.Size([1, 4]), Device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVKcytBEzXNG"
      },
      "source": [
        "class myclass: # la classe è un contenitore (diverse funzioni)\n",
        "    def __init__(self, lista):\n",
        "        # Initial\n",
        "        self.arr = np.array(lista, dtype=np.float32)\n",
        "        #self.device = torch.device(\"cuda:0\")\n",
        "        self.device = torch.device(\"cpu\")\n",
        "        \n",
        "    def arrayToTensor(self):\n",
        "        x = torch.from_numpy(self.arr).to(self.device)\n",
        "        return x\n",
        "    def arrayDouble(self):\n",
        "        x = self.arr*2\n",
        "        return x\n",
        "        \n",
        "cl = myclass([5,7,8,9])\n",
        "p1 = cl.arrayToTensor()\n",
        "p2  = cl.arrayDouble()\n",
        "print(p1.device,p2)\n",
        "\n",
        "cr = myclass([5,16,2,9])\n",
        "pr1 = cr.arrayToTensor()\n",
        "pr2  = cr.arrayDouble()\n",
        "print(pr1,pr2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}